{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re # re.search etc. regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Reference Table:\n",
    "Create a DataFrame that defines your categories, subcategories, and corresponding descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference table for categories and subcategories\n",
    "# ???? CENTER FOR INTUITIVE P WARREN OH\n",
    "# ???? BEACHWOOD PLACE, OH-HC BEACHWOOD OH\n",
    "categories_data = {\n",
    "    # INCOME TAXES FEES ETC EXCLUDE PAYMENTS\n",
    "    'Income': {\n",
    "        'Anita Income': ['ZELLE DEP ANITA'],\n",
    "        'Fidelity Transfer': ['FID '],\n",
    "        'KeyBank Cash-Back': ['KEY REWARDS', 'GIFT FROM KEY BANK']\n",
    "    },\n",
    "    'Taxes': {\n",
    "        'Taxes': ['TAXREFUND', ' IRS ', 'TAX REF', 'RITA']\n",
    "    },\n",
    "    'Fees': {\n",
    "        'Transaction Fees': ['TRANSACTION FEE']\n",
    "    },\n",
    "    'EXCLUDE': {\n",
    "        'Visa Payment': ['INTERNET TRF TO CCA'],\n",
    "        'Visa Payment Received': ['PAYMENT ']\n",
    "    },\n",
    "    # PRESUMABLY CHECKING ACCT\n",
    "    'Housing': {\n",
    "        'Mortgage': ['WFHM'],\n",
    "        'Bills n Utilities': ['VERIZON', 'VZWRLSS', 'DOMINION', 'FIRST ENERGY', 'NORTHEAST OHIO', 'CLEVELAND HEIGHTS', 'ENBRIDGE GAS', 'ATT ', 'NEORSD', 'CWD']\n",
    "    },\n",
    "    'Insurance': {\n",
    "        'Medical Insurance': ['MEDICARE', 'VSP', 'UNITEDHEALTHCARE', 'ROCKWELL', 'AARP HEALTH', 'DELTA DENTAL'],\n",
    "        'Car Insurance': ['LIBERTY MUTUAL']\n",
    "    },\n",
    "    'Education': {\n",
    "        'College Tuition': ['SMARTPAYCIA', 'CASHNET', 'CAMPUS CIA', 'BURREN', 'COLLEGE'],\n",
    "        'Art Supplies': ['UTRECHT', ' ART ']\n",
    "    },\n",
    "    'Professional': {\n",
    "        'Professional Fees': ['LICENSURE', 'LICENSE'],\n",
    "        'Liability Insurance': ['CPH LIABILITY']\n",
    "    },\n",
    "    # PRESUMABLY CREDIT CARD\n",
    "    'Transportation': {\n",
    "        'Gas': ['SUNOCO', 'BP', 'SHELL', 'MARATHON', 'CIRCLE K', 'SHEETZ', 'GAS'],\n",
    "        'Car Maintenance': ['REPAIR', 'AUTO', 'BODY', 'QUALITY AUTO'],\n",
    "        'Car Registration' : ['BUREAU MOTOR VE']\n",
    "    },\n",
    "    'Food': {\n",
    "        'Groceries': ['GROCERY', 'HEINEN', 'DAVE', 'WHOLE', 'SODA', 'TRADE'],\n",
    "        'Dining Out': ['TAVERN', 'TOMMYS', 'CAFE', 'WASABI', 'PACIFIC', 'ANATOLIA', 'BATUQUI', 'PHO', 'LAKE HOUSE', 'DEWEY',\\\n",
    "                        'MAROTTA ', 'BANANA', 'BANGKOK', 'HIBACHI', 'BRASSICA', 'RESTAUR', 'BUFFALO', 'COZUMEL', 'FIRST WATCH',\\\n",
    "                            'PARADISE BIRYANI', 'CARIBOU COFFEE', 'STONE OVEN', 'SEOUL GARDEN ', 'YOURS TRULY', 'LOCKKEEPERS' ],\n",
    "        'Fast Food': ['LEFTY', 'SHAKE SHACK', 'SHAKESHACK', 'WENDY', 'BUDDA', 'CILANTRO', 'PANERA', 'CHIPOTLE', 'BIBIBOP', 'ROGERS', 'PIADA',\\\n",
    "                      'ZINA', 'SUBSHOPPE', 'NATURES OASIS', 'LOTUS EXPRESS', 'BRUEGGERS '],\n",
    "        'World Food': ['KRAKOW', 'NIPA HUT', 'YELESEYEVSKY'],\n",
    "        'Why DOORDASH?': ['DOORDASH']\n",
    "    },\n",
    "    'Health & Beauty': {\n",
    "        'Aikido n Yoga': ['CHECK', ' YOGA'], \n",
    "        'Beauty n Supplies': ['LADIES', 'BATH', 'SALLY BEAUTY', 'AVEDA', 'LUSH BEACHWOOD', 'AIKIKAI', 'AIKIDO', 'ATMA', 'PADDLE'],\n",
    "        'Sound Bath': ['PAYPAL INST'], # ?????\n",
    "         # CLEVELAND KIDNEY & HYP - tomek's kidney USG ?\n",
    "        'Medical and Dental': ['PEDIATRICS', 'CLEVELAND CLINIC', 'METROHEALTH', 'WESTERN RESERVE PERIO', 'HILLCREST ', 'CLEVELAND KIDNEY '],\n",
    "        'Pharmacy': ['CVS', 'WALGREENS']\n",
    "    },\n",
    "    'Home & Garden': {\n",
    "        'House Maintenance': ['HOME DEPOT'],\n",
    "        'Furnishing': ['WORLD', 'REFURNISHING', 'KOALA', 'WAYFAIR'],\n",
    "        'Garden': ['BREMEC', 'LANDSCAPE', 'STUMP', 'NATURE CENTER']\n",
    "    },\n",
    "    'Subscriptions': {\n",
    "        'Subscription': ['SPOTIFY', 'APPLE', 'NETFLIX', 'AUDIBLE', 'PEACOCK', 'WALL', 'BITDEFENDER', 'MICROSOFT', 'HULU', 'NYTIMES', 'IDEASTREAM', 'WSJ']\n",
    "    },\n",
    "    'Shopping': {\n",
    "        'Amazon': ['AMAZON', 'AMZN'],\n",
    "        'Department Store': ['TARGET', 'MACY'],\n",
    "        # BEACHWOOD PLACE, OH-HC BEACHWOOD OH =? Ann Taylor store in beachwood place\n",
    "        'Clothes': ['REI', 'NORDSTROM', 'DICK', 'DSW', 'AVALON', 'MARSHALLS', 'ANN TAYLOR', 'AMERICAN EAGLE', 'FOOTWEAR', 'H&M ', 'OLD NAVY '],\n",
    "        'Kindle n Books': ['KINDLE', 'AUDIOTEKA', 'LOGANBERRY', 'MAC\\'S', 'EMPIK'],\n",
    "        # SERIF.COMBILL MINNETONKA MN = AFFINITY GRAPHICS SOFTWARE\n",
    "        # SIMON HAYNES T AIAT PAYPAL = SpaceJock Writing software\n",
    "        'Software n Accessories': ['SIMON HAYNES', 'ALISTORE', 'GOOGLE', 'FLIXEASY', 'CLIP STUDIO', 'ALIEXPRESS', 'SERIF.COMBILL MINNETONKA MN'],\n",
    "        # LOTUS FLOWER LLC = flowers to Poland\n",
    "        'Gifts': ['FIDDLEHEAD', 'PASSPORT', 'DIAMONDS FLOWERS', 'BUNDT', 'ALL CITY CANDY', 'LOTUS FLOWER LLC', 'PINKBLUSHMATERNIT',\\\n",
    "                  'LITTLE ROOM ', 'CRAFT COLLECTIVE'],\n",
    "        # THE CHILDRENS PLACE 42 BEACHWOOD OH \n",
    "        # THECHILDRENSPLACE.COM SECAUCUS NJ\n",
    "        'Kids Toys': ['PLAYMATTERS', 'DISNEYSTORE', 'CHILDRENS PLACE', 'THECHILDRENSPLACE.COM' ],\n",
    "        'Cycling n Paddling' : ['BIKES', 'IROCKER']\n",
    "    },\n",
    "    'Pets': {\n",
    "        'Cat Food n Supplies': ['PET', 'CHEWY', 'HOLLYWOOD FEED', 'JACKSON GALAXY'],\n",
    "        'Cat Health': ['VETERINARY']\n",
    "    },\n",
    "    # ENTERTAINMENT n GIFTS\n",
    "            # MOVIES THEATER COMPUTER GAMES BIRTHDAY CAKES BDAY DINNERS ETC\n",
    "            # NOTE: CLEVELAND INSTITUTE OF CLEVELAND ==== CIA CINEMATEQUE\n",
    "            # MUSEUM ===== includes THE CHILDRENS MUSEUM O CLEVELAND OH \n",
    "            # GREATER CLEVELAND AQUA ==== CLEVELAND AQUARIUM\n",
    "            # MANGO MANGO DESSE CLEVELAND ===== mango mango dessert Sof's birthday with Felix\n",
    "            # DIAMONDS FLOWERS ========= flower shop Coventry\n",
    "    'Entertainment': {\n",
    "        # METROPARKS FARMPA KIRTLAND - Farm Park Kirtland w Kiddos\n",
    "        'Fun Out': ['CLEVELAND MUSEUM OF AR', 'GREATER CLEVELAND AQUA', 'METROPARKS FARMPA KIRTLAND', 'MITCHELL',\\\n",
    "                                      'SWEET FIX', 'MANGO MANGO DESSE',\\\n",
    "                                          'ON THE RISE', 'RISING STAR COFFEE', 'STARBUCKS', 'MICHAELS', 'UPTOWN MART', 'ELLIE-MAYS', '6 FLAVORS INDIAN', 'LUXE KITCHEN'],\n",
    "        'Movies n Theater': ['VUDU', 'FANDANGO', 'DOBAMA','THEAT', 'CLEVELAND PUBLIC', 'CLEVELAND INSTITUTE OF CLEVELAND',\\\n",
    "                                   'MOVIE', 'PRIME VIDEO', 'BORDERLIGHT', 'CINEMA'],\n",
    "        'Music n Games': ['STEAMGAMES', 'BANDCAMP'],\n",
    "        # Cleveland Museum Cleveland OH - Cleveland Museum of Art membership\n",
    "        'Memberships': ['Cleveland Museum Cleveland OH']\n",
    "    },\n",
    "    # PY *PCRF LOS ANGELES CA - Palestine children relief fund ??? \n",
    "    'Miscellaneous': {\n",
    "        'Political Donations': ['ACTBLUE'],\n",
    "        'ATM Wthdrw n Dpsit' : ['ATM '],\n",
    "        'Vending Machines' : ['VENDING ', 'PEPSIVEN'],\n",
    "        'Parcels' : ['USPS ']\n",
    "    },\n",
    "    # EXCEPTIONS - PROCESS LAST\n",
    "    'Travel': {\n",
    "        # HNDISCOVER ST728 CLEVELAND OH = Hopkins airport  \n",
    "        # Espresso House 7187 Kastrup DNK = Copenhagen Airport\n",
    "        'Air Travel': ['LOT ', 'AMERICAN', 'EXPEDIA', 'SAS ', 'EAT AND GO JAMAICA', ' Kastrup', 'HUDSONNEWS ', 'HUDSON',\\\n",
    "                       'HNDISCOVER', 'JFK ', 'MIDTOWN BISTRO', 'TST* ', 'CURRITO '],\n",
    "        'Visiting Grandma Ela': ['PLUSKI', 'OLSZTYN', 'WARSZAWA', re.compile(r' POL$'), re.compile(r' CHICAGO IL$')],\n",
    "        'Vacation SC': ['FOLLY', 'VIATORTRIPADVISOR', 'VACASA', 'VRBO', re.compile(r' SC$'), re.compile(r' NC$'), re.compile(r' WV$')],\n",
    "        'Visiting Wanda': [re.compile(r' VA$'), re.compile(r' GA$'), re.compile(r' MD$')],\n",
    "        'Visiting Eva': ['PITTSBURGH', 'TURNPIKE', re.compile(r' PA$')]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Integrity of categories definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates(data):\n",
    "    subcategory_seen = set()\n",
    "    keyword_seen = set()\n",
    "    duplicate_subcategories = []\n",
    "    duplicate_keywords = []\n",
    "\n",
    "    for category, subcategories in data.items():\n",
    "        for subcategory, keywords in subcategories.items():\n",
    "            # Check for duplicate subcategories\n",
    "            if subcategory in subcategory_seen:\n",
    "                duplicate_subcategories.append(subcategory)\n",
    "            else:\n",
    "                subcategory_seen.add(subcategory)\n",
    "            \n",
    "            # Check for duplicate keywords\n",
    "            for keyword in keywords:\n",
    "                if isinstance(keyword, re.Pattern):\n",
    "                    keyword = keyword.pattern  # Convert regex to string for comparison\n",
    "                \n",
    "                if keyword in keyword_seen:\n",
    "                    duplicate_keywords.append(keyword)\n",
    "                else:\n",
    "                    keyword_seen.add(keyword)\n",
    "    \n",
    "    return duplicate_subcategories, duplicate_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicates_and_substrings(data):\n",
    "    subcategory_seen = set()\n",
    "    keyword_seen = set()\n",
    "    duplicate_subcategories = []\n",
    "    duplicate_keywords = []\n",
    "    substring_subcategories = []\n",
    "    substring_keywords = []\n",
    "\n",
    "    for category, subcategories in data.items():\n",
    "        for subcategory, keywords in subcategories.items():\n",
    "            # Check for duplicate subcategories\n",
    "            if subcategory in subcategory_seen:\n",
    "                duplicate_subcategories.append(subcategory)\n",
    "            else:\n",
    "                subcategory_seen.add(subcategory)\n",
    "            \n",
    "            # Check for subcategory substrings\n",
    "            for seen_sub in subcategory_seen:\n",
    "                if seen_sub != subcategory and (subcategory in seen_sub or seen_sub in subcategory):\n",
    "                    substring_subcategories.append((subcategory, seen_sub))\n",
    "            \n",
    "            # Check for duplicate keywords\n",
    "            for keyword in keywords:\n",
    "                if isinstance(keyword, re.Pattern):\n",
    "                    keyword_str = keyword.pattern  # Convert regex to string for comparison\n",
    "                else:\n",
    "                    keyword_str = keyword\n",
    "                \n",
    "                if keyword_str in keyword_seen:\n",
    "                    duplicate_keywords.append(keyword_str)\n",
    "                else:\n",
    "                    keyword_seen.add(keyword_str)\n",
    "\n",
    "                # Check for keyword substrings\n",
    "                for seen_kw in keyword_seen:\n",
    "                    if seen_kw != keyword_str and (keyword_str in seen_kw or seen_kw in keyword_str):\n",
    "                        substring_keywords.append((keyword_str, seen_kw))\n",
    "    \n",
    "    return duplicate_subcategories, duplicate_keywords, substring_subcategories, substring_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates and substrings in categories_data\n",
    "duplicate_subcategories, duplicate_keywords, substring_subcategories, substring_keywords = find_duplicates_and_substrings(categories_data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Duplicate Subcategories:\")\n",
    "print(duplicate_subcategories if duplicate_subcategories else \"None\")\n",
    "\n",
    "print(\"\\nDuplicate Keywords:\")\n",
    "print(duplicate_keywords if duplicate_keywords else \"None\")\n",
    "\n",
    "print(\"\\nSubstring Subcategories:\")\n",
    "print(substring_subcategories if substring_subcategories else \"None\")\n",
    "\n",
    "print(\"\\nSubstring Keywords:\")\n",
    "print(substring_keywords if substring_keywords else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates in categories_data\n",
    "duplicate_subcategories, duplicate_keywords = find_duplicates(categories_data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Duplicate Subcategories:\")\n",
    "print(duplicate_subcategories if duplicate_subcategories else \"None\")\n",
    "\n",
    "print(\"\\nDuplicate Keywords:\")\n",
    "print(duplicate_keywords if duplicate_keywords else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the hierarchical dictionary into a DataFrame for easier processing\n",
    "categories_list = []\n",
    "for category, subcategories in categories_data.items():\n",
    "    for subcategory, keywords in subcategories.items():\n",
    "        categories_list.append({'Category': category, 'Subcategory': subcategory, 'DescriptionKeywords': keywords})\n",
    "\n",
    "categories_df = pd.DataFrame(categories_list)\n",
    "\n",
    "print(categories_list)\n",
    "print(categories_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Categorize Transactions:\n",
    "Create a function that uses the reference table to categorize transactions based on the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using iterrows() to iterate over rows\n",
    "for index, row in categories_df.iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"Row: {row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_transaction(description, categories_df):\n",
    "    description_upper = description.upper() \n",
    "    for index, row in categories_df.iterrows():\n",
    "        for keyword in row['DescriptionKeywords']:\n",
    "            if isinstance(keyword, str) and keyword in description_upper:\n",
    "                return row['Category'], row['Subcategory']\n",
    "            elif isinstance(keyword, re.Pattern) and keyword.search(description_upper):\n",
    "                return row['Category'], row['Subcategory']\n",
    "    return 'Uncategorized', 'Uncategorized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_append(file_path, current_df):\n",
    "    \"\"\"\n",
    "    Load an Excell file and append its content to the current DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, the path to the new file\n",
    "    - current_df: pd.DataFrame, the current DataFrame\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame, the updated DataFrame with the new data appended\n",
    "    \"\"\"\n",
    "    # Load the new DataFrame from the Excell file\n",
    "    new_df = pd.read_excel(file_path)\n",
    "\n",
    "    # Append the new DataFrame to the current DataFrame\n",
    "    updated_df = pd.concat([current_df, new_df], ignore_index=True)\n",
    "\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expenses(year_month):\n",
    "    # Load the CSV files with credit card and checking card records\n",
    "    creditcard_filename = year_month + '-A&T-CCard.xlsx'\n",
    "    checking_filename = year_month + '-A&T-CheckingAcct.xlsx'\n",
    "\n",
    "    df_credit = pd.read_excel(creditcard_filename)\n",
    "    df_checking = pd.read_excel(checking_filename)\n",
    "    print(df_credit.head())\n",
    "    print(df_checking.head())\n",
    "\n",
    "    # Check the first few rows to understand the structure of your data.\n",
    "    df = pd.concat([df_checking, df_credit], ignore_index=True)\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_to_process = ['2024-06','2024-07', '2024-08', '2024-09','2024-10','2024-11','2024-12','2025-01']\n",
    "\n",
    "df  = pd.DataFrame()\n",
    "\n",
    "for month in months_to_process : \n",
    "    df_month = load_expenses(month)\n",
    "    df = pd.concat([df, df_month], ignore_index=True)\n",
    "\n",
    "# Extract the year from the first month in the list\n",
    "year = months_to_process[0][:4]\n",
    "\n",
    "# Extract the months from each entry in the list\n",
    "months = [month[5:] for month in months_to_process]\n",
    "\n",
    "# Concatenate the year and the months together in the desired format\n",
    "# Join the list of months into a single string\n",
    "months_string = \"-\".join(months)\n",
    "\n",
    "# Create the final result string\n",
    "result_string = f\"{year}-{months_string}\"\n",
    "output_datafile_summary = result_string + '-A&T-SUMMARY.csv'\n",
    "categorized_expenses_filename = result_string + '-A&T-CATEGORIZED.csv'\n",
    "\n",
    "print(output_datafile_summary)\n",
    "print(categorized_expenses_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = load_and_append('2024-10-A&T-CCard.xlsx', df)\n",
    "# df = load_and_append('2024-10-A&T-CheckingAcct.xlsx', df)\n",
    "# df = load_and_append('2024-11-A&T-CCard.xlsx', df)\n",
    "# df = load_and_append('2024-11-A&T-CheckingAcct.xlsx', df)\n",
    "# df = load_and_append('2024-12-A&T-CCard.xlsx', df)\n",
    "# df = load_and_append('2024-12-A&T-CheckingAcct.xlsx', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize the transactions:\n",
    "\n",
    "Add a new column for categories. You can create a function to categorize transactions based on the description or other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the function to categorize transactions\n",
    "df[['Category', 'Subcategory']] = df['Description'].apply(lambda x: pd.Series(categorize_transaction(x, categories_df)))\n",
    "\n",
    "# Filter out rows with 'EXCLUDE' category\n",
    "filtered_df = df[df['Category'] != 'EXCLUDE']\n",
    "\n",
    "sorted_df = filtered_df.sort_values(by=['Category', 'Subcategory'])\n",
    "# Print the categorized DataFrame\n",
    "print(sorted_df)\n",
    "\n",
    "sorted_df.to_csv(categorized_expenses_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the date column to datetime:\n",
    "\n",
    "Ensure the date column is in datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to datetime:\n",
    "# Ensure the date column is in datetime format.\n",
    "\n",
    "sorted_df['Date'] = pd.to_datetime(sorted_df['Date'])\n",
    "\n",
    "#Group by month:\n",
    "# Extract the month and year from the date column and group the data by these values.\n",
    "\n",
    "sorted_df['YearMonth'] = sorted_df['Date'].dt.to_period('M')\n",
    "\n",
    "# Summarize expenses by category for each month\n",
    "monthly_expenses = sorted_df.groupby(['YearMonth', 'Category'])['Amount'].sum().unstack().fillna(0)\n",
    "\n",
    "# Transpose the DataFrame\n",
    "monthly_expenses_transposed = monthly_expenses.T\n",
    "\n",
    "# Reset index to make 'Category' a column\n",
    "monthly_expenses_transposed = monthly_expenses_transposed.reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "monthly_expenses_transposed.columns.name = None\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(monthly_expenses_transposed)\n",
    "monthly_expenses_transposed.to_csv(output_datafile_summary, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze and visualize the data:\n",
    "\n",
    "You can now analyze the monthly expenses by category and create visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reorder expense categories for display\n",
    "display_order = ['Income',\\\n",
    "                'Housing',\\\n",
    "                'Insurance',\\\n",
    "                'Food',\\\n",
    "                'Subscriptions',\\\n",
    "                'Transportation',\\\n",
    "                'Health & Beauty',\\\n",
    "                'Shopping',\\\n",
    "                'Home & Garden',\\\n",
    "                'Pets',\\\n",
    "                'Entertainment',\\\n",
    "                'Professional',\\\n",
    "                'Taxes',\\\n",
    "                'Education',\\\n",
    "                'Travel',\\\n",
    "                'Fees',\\\n",
    "                'Uncategorized'\n",
    "                    ]\n",
    "# Reorder the columns in the DataFrame according to the desired order\n",
    "monthly_expenses = monthly_expenses[display_order]\n",
    "\n",
    "\n",
    "# Define your custom colors for each category\n",
    "# Get the list of unique categories in your data\n",
    "categories = monthly_expenses.columns\n",
    "# Map the colors to the categories\n",
    "colors = [category_colors[cat] for cat in categories]\n",
    "category_colors = {\n",
    "    'Food': '#1f77b4',  # Blue\n",
    "    'Shopping': '#FF6666', # Light Red\n",
    "    'Housing': '#2ca02c',  # Green\n",
    "    'Income' : '#D3D3D3', # Light Gray \n",
    "    'Travel' : '#8B0000', # Dark Red\n",
    "    'Education' : '#800080', # Purple\n",
    "    'Entertainment' : '#FF00FF', # Magenta\n",
    "    'Fees'  : '#FF0000', # Red\n",
    "    'Health & Beauty' : '#FFC0CB', # Pink\n",
    "    'Home & Garden' : '#FFA500', # Orange\n",
    "    'Insurance' : '#FFFF00', # Yellow\n",
    "    'EXCLUDE' : '#FF6666', # Light Red\n",
    "    'Pets' : '#8A2BE2', # Violet\n",
    "    'Miscellaneous' : '#708090', # Slate Gray\n",
    "    'Subscriptions' : '#E6E6FA', # Lavender\n",
    "    'Taxes' : '#696969', # Dim Gray\n",
    "    'Transportation' : '#708090', # Slate Gray\n",
    "    'Uncategorized' : '#000000', # Black\n",
    "    'Professional' : '#FF8C00', # Dark Orange\n",
    "\n",
    "    # Add more categories and colors as needed\n",
    "    # '#FFFF00', # Yellow\n",
    "    # '#FF0000', # Red\n",
    "    # '#800080', # Purple\n",
    "    # '#8A2BE2', # Violet\n",
    "    # '#FFA500', # Orange\n",
    "    # '#FFC0CB', # Pink\n",
    "    # '#FF00FF', # Magenta\n",
    "    # '#D8BFD8', # Light Purple\n",
    "    # '#E6E6FA', # Lavender\n",
    "    # '#FF6666', # Light Red\n",
    "    # '#FFFFE0', # Light Yellow\n",
    "    # '#FF8C00', # Dark Orange\n",
    "    # '#8B0000', # Dark Red\n",
    "    # '#FF1493', # Deep Pink\n",
    "    # '#D3D3D3', # Light Gray \n",
    "    # '#708090', # Slate Gray\n",
    "    # '#696969', # Dim Gray\n",
    "    # '#000000', # Black\n",
    "}\n",
    "\n",
    "# Plot monthly expenses by category\n",
    "monthly_expenses.plot(kind='bar', stacked=True, figsize=(10, 6), color=colors, width=1)\n",
    "plt.title('Monthly Expenses by Category')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Amount ($)')\n",
    "\n",
    "# Move the legend to the best location\n",
    "# plt.legend(loc='best')\n",
    "# Move the legend to the outside right of the plot\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ant-finances-analysis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
