{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re # re.search etc. regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Reference Table:\n",
    "Create a DataFrame that defines your categories, subcategories, and corresponding descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference table for categories and subcategories\n",
    "# ???? CENTER FOR INTUITIVE P WARREN OH\n",
    "# ???? BEACHWOOD PLACE, OH-HC BEACHWOOD OH\n",
    "categories_data = {\n",
    "    # INCOME TAXES FEES ETC EXCLUDE PAYMENTS\n",
    "    'INCOME': {\n",
    "        'Anita Income': ['ZELLE DEP ANITA'],\n",
    "        'Fidelity Transfer': ['FID '],\n",
    "        'KeyBank Cash-Back': ['KEY REWARDS', 'GIFT FROM KEY BANK']\n",
    "    },\n",
    "    'TAXES': {\n",
    "        'Taxes': ['TAXREFUND', ' IRS ', 'TAX REF', 'RITA']\n",
    "    },\n",
    "    'FEES': {\n",
    "        'Transaction Fees': ['TRANSACTION FEE']\n",
    "    },\n",
    "    'EXCLUDE': {\n",
    "        'Visa Payment': ['INTERNET TRF TO CCA'],\n",
    "        'Visa Payment Received': ['PAYMENT ']\n",
    "    },\n",
    "    # PRESUMABLY CHECKING ACCT\n",
    "    'HOUSING': {\n",
    "        'Mortgage': ['WFHM'],\n",
    "        'Bills n Utilities': ['VERIZON', 'VZWRLSS', 'DOMINION', 'FIRST ENERGY', 'NORTHEAST OHIO', 'CLEVELAND HEIGHTS', 'ENBRIDGE GAS', 'ATT ', 'NEORSD', 'CWD']\n",
    "    },\n",
    "    'HEALTHCARE': {\n",
    "        'Medical Insurance': ['MEDICARE', 'VSP', 'UNITEDHEALTHCARE', 'ROCKWELL', 'AARP HEALTH', 'DELTA DENTAL'],\n",
    "         # CLEVELAND KIDNEY & HYP - tomek's kidney USG ?\n",
    "        'Medical and Dental': ['PEDIATRICS', 'CLEVELAND CLINIC', 'METROHEALTH', 'WESTERN RESERVE PERIO', 'HILLCREST ', 'CLEVELAND KIDNEY '],\n",
    "        'Pharmacy': ['CVS', 'WALGREENS']\n",
    "    },\n",
    "    'EDUCATION': {\n",
    "        'College Tuition': ['SMARTPAYCIA', 'CASHNET', 'CAMPUS CIA', 'BURREN', 'COLLEGE'],\n",
    "        'Art Supplies': ['UTRECHT', ' ART ']\n",
    "    },\n",
    "    'PROFESSIONAL': {\n",
    "        'Professional Fees': ['LICENSURE', 'LICENSE'],\n",
    "        'Liability Insurance': ['CPH LIABILITY']\n",
    "    },\n",
    "    # PRESUMABLY CREDIT CARD\n",
    "    'TRANSPORTATION': {\n",
    "        'Gas': ['SUNOCO', 'BP', 'SHELL', 'MARATHON', 'CIRCLE K', 'SHEETZ', 'GAS'],\n",
    "        'Car Maintenance': ['REPAIR', 'AUTO', 'BODY', 'QUALITY AUTO'],\n",
    "        'Car Registration' : ['BUREAU MOTOR VE'],\n",
    "        'Car Insurance': ['LIBERTY MUTUAL']\n",
    "    },\n",
    "    'FOOD': {\n",
    "        'Groceries': ['GROCERY', 'HEINEN', 'DAVE', 'WHOLE', 'SODA', 'TRADE'],\n",
    "        'Dining Out': ['TAVERN', 'TOMMYS', 'CAFE', 'WASABI', 'PACIFIC', 'ANATOLIA', 'BATUQUI', 'PHO', 'LAKE HOUSE', 'DEWEY',\\\n",
    "                        'MAROTTA ', 'BANANA', 'BANGKOK', 'HIBACHI', 'BRASSICA', 'RESTAUR', 'BUFFALO', 'COZUMEL', 'FIRST WATCH',\\\n",
    "                            'PARADISE BIRYANI', 'CARIBOU COFFEE', 'STONE OVEN', 'SEOUL GARDEN ', 'YOURS TRULY', 'LOCKKEEPERS' ],\n",
    "        'Fast Food': ['LEFTY', 'SHAKE SHACK', 'SHAKESHACK', 'WENDY', 'BUDDA', 'CILANTRO', 'PANERA', 'CHIPOTLE', 'BIBIBOP', 'ROGERS', 'PIADA',\\\n",
    "                      'ZINA', 'SUBSHOPPE', 'NATURES OASIS', 'LOTUS EXPRESS', 'BRUEGGERS '],\n",
    "        'World Food': ['KRAKOW', 'NIPA HUT', 'YELESEYEVSKY'],\n",
    "        'Why DOORDASH?': ['DOORDASH']\n",
    "    },\n",
    "    'SELFCARE & WELLBEING': {\n",
    "        'Aikido n Yoga': ['CHECK', ' YOGA'], \n",
    "        'Beauty n Supplies': ['LADIES', 'BATH', 'SALLY BEAUTY', 'AVEDA', 'LUSH BEACHWOOD', 'AIKIKAI', 'AIKIDO', 'ATMA', 'PADDLE'],\n",
    "        'Sound Bath': ['PAYPAL INST'], # ?????\n",
    "    },\n",
    "    'HOME & GARDEN': {\n",
    "        'House Maintenance': ['HOME DEPOT'],\n",
    "        'Furnishing': ['WORLD', 'REFURNISHING', 'KOALA', 'WAYFAIR'],\n",
    "        'Garden': ['BREMEC', 'LANDSCAPE', 'STUMP', 'NATURE CENTER']\n",
    "    },\n",
    "    'SUBSCRIPTIONS': {\n",
    "        'Subscription': ['SPOTIFY', 'APPLE', 'NETFLIX', 'AUDIBLE', 'PEACOCK', 'WALL', 'BITDEFENDER', 'MICROSOFT', 'HULU', 'NYTIMES', 'IDEASTREAM', 'WSJ']\n",
    "    },\n",
    "    'SHOPPING': {\n",
    "        'Amazon': ['AMAZON', 'AMZN'],\n",
    "        'Department Store': ['TARGET', 'MACY'],\n",
    "        # BEACHWOOD PLACE, OH-HC BEACHWOOD OH =? Ann Taylor store in beachwood place\n",
    "        'Clothes': ['REI', 'NORDSTROM', 'DICK', 'DSW', 'AVALON', 'MARSHALLS', 'ANN TAYLOR', 'AMERICAN EAGLE', 'FOOTWEAR', 'H&M ', 'OLD NAVY '],\n",
    "        'Kindle n Books': ['KINDLE', 'AUDIOTEKA', 'LOGANBERRY', 'MAC\\'S', 'EMPIK'],\n",
    "        # SERIF.COMBILL MINNETONKA MN = AFFINITY GRAPHICS SOFTWARE\n",
    "        # SIMON HAYNES T AIAT PAYPAL = SpaceJock Writing software\n",
    "        'Software n Accessories': ['SIMON HAYNES', 'ALISTORE', 'GOOGLE', 'FLIXEASY', 'CLIP STUDIO', 'ALIEXPRESS', 'SERIF.COMBILL MINNETONKA MN'],\n",
    "        # LOTUS FLOWER LLC = flowers to Poland\n",
    "        'Gifts': ['FIDDLEHEAD', 'PASSPORT', 'DIAMONDS FLOWERS', 'BUNDT', 'ALL CITY CANDY', 'LOTUS FLOWER LLC', 'PINKBLUSHMATERNIT',\\\n",
    "                  'LITTLE ROOM ', 'CRAFT COLLECTIVE'],\n",
    "        # THE CHILDRENS PLACE 42 BEACHWOOD OH \n",
    "        # THECHILDRENSPLACE.COM SECAUCUS NJ\n",
    "        'Kids Toys': ['PLAYMATTERS', 'DISNEYSTORE', 'CHILDRENS PLACE', 'THECHILDRENSPLACE.COM' ],\n",
    "        'Cycling n Paddling' : ['BIKES', 'IROCKER']\n",
    "    },\n",
    "    'PETS': {\n",
    "        'Cat Food n Supplies': ['PET', 'CHEWY', 'HOLLYWOOD FEED', 'JACKSON GALAXY'],\n",
    "        'Cat Health': ['VETERINARY']\n",
    "    },\n",
    "    # ENTERTAINMENT n GIFTS\n",
    "            # MOVIES THEATER COMPUTER GAMES BIRTHDAY CAKES BDAY DINNERS ETC\n",
    "            # NOTE: CLEVELAND INSTITUTE OF CLEVELAND ==== CIA CINEMATEQUE\n",
    "            # MUSEUM ===== includes THE CHILDRENS MUSEUM O CLEVELAND OH \n",
    "            # GREATER CLEVELAND AQUA ==== CLEVELAND AQUARIUM\n",
    "            # MANGO MANGO DESSE CLEVELAND ===== mango mango dessert Sof's birthday with Felix\n",
    "            # DIAMONDS FLOWERS ========= flower shop Coventry\n",
    "    'ENTERTAINMENT': {\n",
    "        # METROPARKS FARMPA KIRTLAND - Farm Park Kirtland w Kiddos\n",
    "        'Fun Out': ['CLEVELAND MUSEUM OF AR', 'GREATER CLEVELAND AQUA', 'METROPARKS FARMPA KIRTLAND', 'MITCHELL',\\\n",
    "                                      'SWEET FIX', 'MANGO MANGO DESSE',\\\n",
    "                                          'ON THE RISE', 'RISING STAR COFFEE', 'STARBUCKS', 'MICHAELS', 'UPTOWN MART', 'ELLIE-MAYS', '6 FLAVORS INDIAN', 'LUXE KITCHEN'],\n",
    "        'Movies n Theater': ['VUDU', 'FANDANGO', 'DOBAMA','THEAT', 'CLEVELAND PUBLIC', 'CLEVELAND INSTITUTE OF CLEVELAND',\\\n",
    "                                   'MOVIE', 'PRIME VIDEO', 'BORDERLIGHT', 'CINEMA'],\n",
    "        'Music n Games': ['STEAMGAMES', 'BANDCAMP'],\n",
    "        # Cleveland Museum Cleveland OH - Cleveland Museum of Art membership\n",
    "        'Memberships': ['Cleveland Museum Cleveland OH']\n",
    "    },\n",
    "    # PY *PCRF LOS ANGELES CA - Palestine children relief fund ??? \n",
    "    'MISCELLANEOUS': {\n",
    "        'Political Donations': ['ACTBLUE'],\n",
    "        'ATM Wthdrw n Dpsit' : ['ATM '],\n",
    "        'Vending Machines' : ['VENDING ', 'PEPSIVEN'],\n",
    "        'Parcels' : ['USPS ']\n",
    "    },\n",
    "    # EXCEPTIONS - PROCESS LAST\n",
    "    'VACATIONS & TRAVEL': {\n",
    "        # HNDISCOVER ST728 CLEVELAND OH = Hopkins airport  \n",
    "        # Espresso House 7187 Kastrup DNK = Copenhagen Airport\n",
    "        'Air Travel': ['LOT ', 'AMERICAN', 'EXPEDIA', 'SAS ', 'EAT AND GO JAMAICA', ' Kastrup', 'HUDSONNEWS ', 'HUDSON',\\\n",
    "                       'HNDISCOVER', 'JFK ', 'MIDTOWN BISTRO', 'TST* ', 'CURRITO '],\n",
    "        'Visiting Grandma Ela': ['PLUSKI', 'OLSZTYN', 'WARSZAWA', re.compile(r' POL$'), re.compile(r' CHICAGO IL$')],\n",
    "        'Vacation SC': ['FOLLY', 'VIATORTRIPADVISOR', 'VACASA', 'VRBO', re.compile(r' SC$'), re.compile(r' NC$'), re.compile(r' WV$')],\n",
    "        'Visiting Wanda': [re.compile(r' VA$'), re.compile(r' GA$'), re.compile(r' MD$')],\n",
    "        'Visiting Eva': ['PITTSBURGH', 'TURNPIKE', re.compile(r' PA$')]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom display order and colors for your categories \n",
    "categories_order_and_colors = [\n",
    "    ('INCOME', '#D3D3D3'),  # Light Gray\n",
    "    ('HOUSING', '#2ca02c'),  # Green\n",
    "    ('HEALTHCARE', '#FFFF00'),  # Yellow\n",
    "    ('FOOD', '#1f77b4'),  # Blue\n",
    "    ('SUBSCRIPTIONS', '#E6E6FA'),  # Lavender\n",
    "    ('TRANSPORTATION', '#708090'),  # Slate Gray\n",
    "    ('SELFCARE & WELLBEING', '#FFC0CB'),  # Pink\n",
    "    ('SHOPPING', '#FF6666'),  # Light Red\n",
    "    ('HOME & GARDEN', '#FFA500'),  # Orange\n",
    "    ('PETS', '#8A2BE2'),  # Violet\n",
    "    ('ENTERTAINMENT', '#FF00FF'),  # Magenta\n",
    "    ('PROFESSIONAL', '#FF8C00'),  # Dark Orange\n",
    "    ('TAXES', '#696969'),  # Dim Gray\n",
    "    ('EDUCATION', '#800080'),  # Purple\n",
    "    ('VACATIONS & TRAVEL', '#8B0000'),  # Dark Red\n",
    "    ('FEES', '#FF0000'),  # Red\n",
    "    ('UNCATEGORIZED', '#000000')  # Black\n",
    "]\n",
    "\n",
    "# Unzip the array to get the display order and colors as separate lists\n",
    "display_order, colors = zip(*categories_order_and_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Integrity of categories definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates and substrings in categories, subcategories, and keywords   \n",
    "def find_all_duplicates_and_substrings(data):\n",
    "    subcategory_seen = set()\n",
    "    keyword_seen = set()\n",
    "    duplicate_subcategories = set()\n",
    "    duplicate_keywords = set()\n",
    "    substring_subcategories = set()\n",
    "    substring_keywords = set()\n",
    "\n",
    "    # Collect all subcategories and keywords first\n",
    "    all_subcategories = []\n",
    "    all_keywords = []\n",
    "\n",
    "    for category, subcategories in data.items():\n",
    "        for subcategory, keywords in subcategories.items():\n",
    "            all_subcategories.append(subcategory)\n",
    "            for keyword in keywords:\n",
    "                if isinstance(keyword, re.Pattern):\n",
    "                    all_keywords.append(keyword.pattern)\n",
    "                else:\n",
    "                    all_keywords.append(keyword)\n",
    "\n",
    "    # Check for duplicate and substring subcategories\n",
    "    for i, subcategory in enumerate(all_subcategories):\n",
    "        for j, other_subcategory in enumerate(all_subcategories):\n",
    "            if i != j:\n",
    "                # Check for duplicates\n",
    "                if subcategory == other_subcategory:\n",
    "                    duplicate_subcategories.add(subcategory)\n",
    "                # Check for substrings\n",
    "                if subcategory in other_subcategory or other_subcategory in subcategory:\n",
    "                    substring_subcategories.add((subcategory, other_subcategory))\n",
    "\n",
    "    # Check for duplicate and substring keywords\n",
    "    for i, keyword in enumerate(all_keywords):\n",
    "        for j, other_keyword in enumerate(all_keywords):\n",
    "            if i != j:\n",
    "                # Check for duplicates\n",
    "                if keyword == other_keyword:\n",
    "                    duplicate_keywords.add(keyword)\n",
    "                # Check for substrings\n",
    "                if keyword in other_keyword or other_keyword in keyword:\n",
    "                    substring_keywords.add((keyword, other_keyword))\n",
    "\n",
    "    return duplicate_subcategories, duplicate_keywords, substring_subcategories, substring_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates and substrings in categories_data\n",
    "duplicate_subcategories, duplicate_keywords, substring_subcategories, substring_keywords = find_all_duplicates_and_substrings(categories_data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Duplicate Subcategories:\")\n",
    "print(duplicate_subcategories if duplicate_subcategories else \"None\")\n",
    "\n",
    "print(\"\\nDuplicate Keywords:\")\n",
    "print(duplicate_keywords if duplicate_keywords else \"None\")\n",
    "\n",
    "print(\"\\nSubstring Subcategories:\")\n",
    "print(substring_subcategories if substring_subcategories else \"None\")\n",
    "\n",
    "print(\"\\nSubstring Keywords:\")\n",
    "print(substring_keywords if substring_keywords else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the hierarchical dictionary into a DataFrame for easier processing\n",
    "categories_list = []\n",
    "for category, subcategories in categories_data.items():\n",
    "    for subcategory, keywords in subcategories.items():\n",
    "        categories_list.append({'Category': category, 'Subcategory': subcategory, 'DescriptionKeywords': keywords})\n",
    "\n",
    "categories_df = pd.DataFrame(categories_list)\n",
    "\n",
    "# print(categories_list)\n",
    "# print(categories_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Categorize Transactions:\n",
    "Create a function that uses the reference table to categorize transactions based on the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using iterrows() to iterate over rows\n",
    "# for index, row in categories_df.iterrows():\n",
    "#     print(f\"Index: {index}\")\n",
    "#     print(f\"Row: {row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize all transactions to category and subcategory based on the description keyword\n",
    "def categorize_transaction(description, categories_df):\n",
    "    description_upper = description.upper() \n",
    "    for index, row in categories_df.iterrows():\n",
    "        for keyword in row['DescriptionKeywords']:\n",
    "            if isinstance(keyword, str) and keyword in description_upper:\n",
    "                return row['Category'], row['Subcategory']\n",
    "            elif isinstance(keyword, re.Pattern) and keyword.search(description_upper):\n",
    "                return row['Category'], row['Subcategory']\n",
    "    return 'UNCATEGORIZED', 'Uncategorized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append new bank record file to the current dataframe \n",
    "def load_and_append(file_path, current_df):\n",
    "    \"\"\"\n",
    "    Load an Excell file and append its content to the current DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, the path to the new file\n",
    "    - current_df: pd.DataFrame, the current DataFrame\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame, the updated DataFrame with the new data appended\n",
    "    \"\"\"\n",
    "    # Load the new DataFrame from the Excell file\n",
    "    new_df = pd.read_excel(file_path)\n",
    "\n",
    "    # Append the new DataFrame to the current DataFrame\n",
    "    updated_df = pd.concat([current_df, new_df], ignore_index=True)\n",
    "\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pair of bank record files for a particular year and month \n",
    "# NOTE - uses standard file naming convention for checking and credit card record  \n",
    "def load_expenses(year_month):\n",
    "    # Load the CSV files with credit card and checking card records\n",
    "    creditcard_filename = year_month + '-A&T-CCard.xlsx'\n",
    "    checking_filename = year_month + '-A&T-CheckingAcct.xlsx'\n",
    "\n",
    "    df_credit = pd.read_excel(creditcard_filename)\n",
    "    df_checking = pd.read_excel(checking_filename)\n",
    "    print(df_credit.head())\n",
    "    print(df_checking.head())\n",
    "\n",
    "    # Check the first few rows to understand the structure of your data.\n",
    "    df = pd.concat([df_checking, df_credit], ignore_index=True)\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main load expense record segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_to_process = ['2024-06','2024-07', '2024-08', '2024-09','2024-10','2024-11','2024-12','2025-01']\n",
    "\n",
    "# Initialize empty dataframe\n",
    "input_df  = pd.DataFrame()\n",
    "\n",
    "# Load a month-worth saving and credit record and append to the current dataframe\n",
    "for month in months_to_process : \n",
    "    df_month = load_expenses(month)\n",
    "    input_df = pd.concat([input_df, df_month], ignore_index=True)\n",
    "\n",
    "# Format the date / range of dates to the output filenames\n",
    "# - extract the year from the first month in the list\n",
    "year = months_to_process[0][:4]\n",
    "# - extract the months from each entry in the list\n",
    "months = [month[5:] for month in months_to_process]\n",
    "# - concatenate the year and the months together in the desired format\n",
    "# - join the list of months into a single string\n",
    "months_string = \"-\".join(months)\n",
    "# - create the final result string\n",
    "result_string = f\"{year}-{months_string}\"\n",
    "output_filename_monthly_expenses = result_string + '-A&T-EXPENSES.xlsx'\n",
    "output_filename_summary_by_cats = result_string + '-A&T-SUMMARY-BY-CATS.csv'\n",
    "output_filename_summary_w_subcats = result_string + '-A&T-SUMMARY-W-SUBCATS.csv'\n",
    "output_filename_categorized_expenses = result_string + '-A&T-CATEGORIZED.csv'\n",
    "\n",
    "print(output_filename_categorized_expenses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize all transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the categorize_transaction function to categorize transactions\n",
    "categorized_expenses_df = input_df\n",
    "# add two columns to the dataframe\n",
    "# df['Description'].apply(lambda x: pd.Series(categorize_transaction(x, categories_df))):\n",
    "#  - this applies the categorize_transaction function to each element in the 'Description' column.\n",
    "#  - the function categorize_transaction is assumed to return a tuple or a list with two elements: the category and the subcategory.\n",
    "# pd.Series(...):\n",
    "#  - converts the output of categorize_transaction (which is a tuple or list) into a pandas Series. This is done for each 'Description' value.\n",
    "# df[['Category', 'Subcategory']]:\n",
    "#  - ssigns the resulting Series to the 'Category' and 'Subcategory' columns in the DataFrame df.\n",
    "categorized_expenses_df[['Category', 'Subcategory']] = input_df['Description'].apply(lambda x: pd.Series(categorize_transaction(x, categories_df)))\n",
    "\n",
    "# Filter out rows with 'EXCLUDE' category\n",
    "filtered_expenses_df = categorized_expenses_df[categorized_expenses_df['Category'] != 'EXCLUDE']\n",
    "\n",
    "# Convert the 'Category' column to a categorical type with the custom order\n",
    "# and reorder the columns in the DataFrame according to the desired order\n",
    "ordered_expenses_df = filtered_expenses_df\n",
    "ordered_expenses_df['Category'] = pd.Categorical(ordered_expenses_df['Category'], categories=display_order, ordered=True)\n",
    "# The following sort_values method will respect this custom order when sorting the 'Category' column. \n",
    "# So, the rows in the sorted_df DataFrame will be sorted according to the custom category order defined in display_order, \n",
    "# followed by the 'Subcategory' column\n",
    "ordered_sorted_expenses_df = ordered_expenses_df.sort_values(by=['Category', 'Subcategory'])\n",
    "\n",
    "# Print the categorized DataFrame\n",
    "print(ordered_sorted_expenses_df)\n",
    "# Save it to a csv file\n",
    "ordered_sorted_expenses_df.to_csv(output_filename_categorized_expenses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Categories only Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to datetime:\n",
    "# Ensure the date column is in datetime format.\n",
    "ordered_sorted_expenses_df['Date'] = pd.to_datetime(ordered_sorted_expenses_df['Date'])\n",
    "\n",
    "# Group by month - extract the month and year from the date column and group the data by these values.\n",
    "ordered_sorted_expenses_df['YearMonth'] = ordered_sorted_expenses_df['Date'].dt.to_period('M')\n",
    "\n",
    "# Summarize expenses by category for each month\n",
    "monthly_expenses = ordered_sorted_expenses_df.groupby(['YearMonth', 'Category'])['Amount'].sum().unstack().fillna(0)\n",
    "\n",
    "# Transpose the DataFrame to print in rows of expenses by columns of months \n",
    "monthly_expenses_summary = monthly_expenses.T\n",
    "# Reset index to make 'Category' a column\n",
    "monthly_expenses_summary = monthly_expenses_summary.reset_index()\n",
    "# Rename columns for clarity\n",
    "monthly_expenses_summary.columns.name = None\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(monthly_expenses_summary)\n",
    "monthly_expenses_summary.to_csv(output_filename_summary_by_cats, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create monthly subcategory summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "# Step 1: Add 'YearMonth' column (assuming 'Date' is in datetime format)\n",
    "categorized_expenses_df['YearMonth'] = categorized_expenses_df['Date'].dt.to_period('M')\n",
    "\n",
    "# Step 2: Group by 'Category', 'Subcategory', and 'YearMonth', and sum 'Amount'\n",
    "grouped_df = categorized_expenses_df.groupby(['Category', 'Subcategory', 'YearMonth'])['Amount'].sum().reset_index()\n",
    "\n",
    "# Step 3: Pivot the table\n",
    "pivot_table = grouped_df.pivot_table(index=['Category', 'Subcategory'], columns='YearMonth', values='Amount', fill_value=0)\n",
    "\n",
    "# Reset the index to flatten the DataFrame\n",
    "pivot_table = pivot_table.reset_index()\n",
    "\n",
    "# Step 4: Calculate the total for each category and append it to the pivot table\n",
    "category_totals = pivot_table.groupby('Category').sum().reset_index()\n",
    "category_totals['Subcategory'] = '<<< TOTAL >>>'\n",
    "subcategories_w_totals_df = pd.concat([pivot_table, category_totals], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame to have the totals at the end of each category\n",
    "subcategories_w_totals_df = subcategories_w_totals_df.sort_values(by=['Category', 'Subcategory']).reset_index(drop=True)\n",
    "\n",
    "# Step 5: Leave the category column blank for subcategories\n",
    "subcategories_w_totals_df.loc[subcategories_w_totals_df['Subcategory'] != '<<< TOTAL >>>', 'Category'] = subcategories_w_totals_df.loc[subcategories_w_totals_df['Subcategory'] != '<<< TOTAL >>>', 'Category'].mask(subcategories_w_totals_df['Category'].duplicated(), '')\n",
    "# Print the final DataFrame\n",
    "print(subcategories_w_totals_df)\n",
    "\n",
    "# Save the final DataFrame to CSV\n",
    "subcategories_w_totals_df.to_csv(output_filename_summary_w_subcats, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write output data to two sheets in an excell file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ExcelWriter to write DataFrames to different sheets\n",
    "with pd.ExcelWriter(output_filename_monthly_expenses, engine='xlsxwriter') as writer:\n",
    "    subcategories_w_totals_df.to_excel(writer, sheet_name='Subcategories', index=False)\n",
    "    monthly_expenses_summary.to_excel(writer, sheet_name='Categories', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze and visualize the data:\n",
    "\n",
    "You can now analyze the monthly expenses by category and create visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reorder the columns in the DataFrame according to the desired order\n",
    "monthly_expenses = monthly_expenses[list(display_order)]\n",
    "\n",
    "# Plot monthly expenses by category\n",
    "monthly_expenses.plot(kind='bar', stacked=True, figsize=(10, 6), color=colors, width=1)\n",
    "plt.title('Monthly Expenses by Category')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Amount ($)')\n",
    "\n",
    "# Move the legend to the best location\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ant-finances-analysis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
