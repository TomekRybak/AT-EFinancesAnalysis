{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed4625d",
   "metadata": {},
   "source": [
    "## üßæ Bank Record Categorization System\n",
    "### Bank Records Analyst (bank_record_analyst.ipynb) \n",
    "###### Note - it superceded categorize_monthly_expenses.ipynb\n",
    "\n",
    "An application to categorize, summarize, and analyze checking and credit card bank records. It provides a modular framework for classifying bank transactions into semantic categories and subcategories using pattern-based matching. It supports both human-readable summaries and programmatic filtering for financial analysis.\n",
    "\n",
    "---\n",
    "### Reads input files from folder: ./data \n",
    "#### DATA NAMING CONVENTION:  2025-08-A&T-CheckingAcct.xlsx / 2025-08-A&T-CCard.xlsx\n",
    "\n",
    "---\n",
    "\n",
    "### üìÇ Data Structures\n",
    "\n",
    "#### `categories_to_subcategories_tree: dict[str, dict[str, dict]]`\n",
    "Defines the hierarchical taxonomy of financial categories and their subcategories.\n",
    "\n",
    "- **Top-level keys** represent broad financial domains (e.g. `'INCOME'`, `'FOOD'`, `'HOUSING'`).\n",
    "- **Nested keys** represent specific subcategories (e.g. `'Anita Income'`, `'Dining Out'`).\n",
    "- Leaf nodes are empty dicts, to keep the datastructure uncluttered and human readible\n",
    "- Leaf nodes are programatically populated with patterns from the second datastructure, allowing flexibility and extensibility.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "'FOOD': {\n",
    "    'Groceries': {},\n",
    "    'Dining Out': {},\n",
    "    'Fast Food': {}\n",
    "}\n",
    "```\n",
    "\n",
    "#### `subcategories_to_patterns: dict[str, list[str | re.Pattern]]`\n",
    "Maps subcategories to lists of string or regex patterns used to identify matching bank record descriptions.\n",
    "- **Patterns** may be **simple substrings** or **compiled regular expressions**.\n",
    "- Enables flexible matching across diverse transaction formats.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "'Bills n Utilities': [\n",
    "    'VERIZON',\n",
    "    'DOMINION',\n",
    "    re.compile(r'ATT\\*BILL')\n",
    "]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_to_subcategories_tree = {\n",
    "    'INCOME': {\n",
    "        'Anita Income': {},\n",
    "        'Fidelity Transfer': {},\n",
    "        'KeyBank Cash-Back': {}\n",
    "    },\n",
    "    'TAXES': {\n",
    "        'Taxes': {}\n",
    "    },\n",
    "    'FEES': {\n",
    "        'Transaction Fees': {}\n",
    "    },\n",
    "    'EXCLUDE': {\n",
    "        'Visa Payment': {},\n",
    "        'Visa Payment Received': {}\n",
    "    },\n",
    "    'HOUSING': {\n",
    "        'Mortgage': {},\n",
    "        'Bills n Utilities': {}\n",
    "    },\n",
    "    'INSURANCE': {\n",
    "        'Medical Insurance': {},\n",
    "        'Car Insurance': {}\n",
    "    },\n",
    "    'HEALTHCARE': {\n",
    "        'Medical and Dental': {},\n",
    "        'Pharmacy': {}\n",
    "    },\n",
    "    'EDUCATION': {\n",
    "        'College Tuition': {},\n",
    "        'Art Supplies': {}\n",
    "    },\n",
    "    'PROFESSIONAL': {\n",
    "        'Professional Fees': {},\n",
    "        'AI API charges': {},\n",
    "        'Professional Services': {},\n",
    "        'Liability Insurance': {}\n",
    "    },\n",
    "    'TRANSPORTATION': {\n",
    "        'Transportation miscellaneous': {},\n",
    "        'Car Registration': {},\n",
    "        'Gas': {},\n",
    "        'Parking and Tolls': {},\n",
    "        'Car Maintenance': {}\n",
    "    },\n",
    "    'FOOD': {\n",
    "        'Groceries': {},\n",
    "        'Dining Out': {},\n",
    "        'Fast Food': {},\n",
    "        'World Food': {},\n",
    "        'Why DOORDASH?': {}\n",
    "    },\n",
    "    'SELFCARE & WELLBEING': {\n",
    "        'Aikido n Yoga': {},\n",
    "        'Beauty n Supplies': {},\n",
    "        'Sound Bath': {}\n",
    "    },\n",
    "    'HOME & GARDEN': {\n",
    "        'House Maintenance': {},\n",
    "        'Furnishing': {},\n",
    "        'Garden': {}\n",
    "    },\n",
    "    'SUBSCRIPTIONS': {\n",
    "        'Subscription': {}\n",
    "    },\n",
    "    'SHOPPING': {\n",
    "        'Amazon': {},\n",
    "        'Department Store': {},\n",
    "        'Clothes': {},\n",
    "        'Kindle n Books': {},\n",
    "        'Software n Accessories': {},\n",
    "        'Computers': {},\n",
    "        'Personal Electronics': {},\n",
    "        'Personal Equipment': {},\n",
    "        'Home Supplies n Decor': {},\n",
    "        'Home Decor': {},\n",
    "        'Gifts': {},\n",
    "        'Kids Toys': {},\n",
    "        'Cycling n Paddling': {}\n",
    "    },\n",
    "    'PETS': {\n",
    "        'Cat Food n Supplies': {},\n",
    "        'Cat Health': {}\n",
    "    },\n",
    "    'ENTERTAINMENT': {\n",
    "        'Fun Out': {},\n",
    "        'Entertaining and Parties': {},\n",
    "        'Movies n Theater': {},\n",
    "        'Music n Games': {},\n",
    "        'Memberships': {}\n",
    "    },\n",
    "    'MISCELLANEOUS': {\n",
    "        'Political Donations': {},\n",
    "        'ATM Wthdrw n Dpsit': {},\n",
    "        'Vending Machines': {},\n",
    "        'Trafic Tickets': {},\n",
    "        'Parcels': {}\n",
    "    },\n",
    "    'VACATIONS & TRAVEL': {\n",
    "        'Trips Out of Town': {},\n",
    "        'Vacation': {},\n",
    "        'Air Travel': {},\n",
    "        'Visiting Grandma Ela': {},\n",
    "        'Vacation SC': {},\n",
    "        'Visiting Wanda': {},\n",
    "        'Visiting Eva': {}\n",
    "    },\n",
    "    'UNCATEGORIZED':{\n",
    "        'Uncategorized'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d307f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re   # regular expressions for complex patterns\n",
    "\n",
    "subcategories_to_patterns = {\n",
    "    'Anita Income': [\n",
    "        'ZELLE DEP ANITA'\n",
    "    ],\n",
    "    'Fidelity Transfer': [\n",
    "        'FID '\n",
    "    ],\n",
    "    'KeyBank Cash-Back': [\n",
    "        'KEY REWARDS',\n",
    "        'GIFT FROM KEY BANK'\n",
    "    ],\n",
    "    'Taxes': [\n",
    "        'TAXREFUND',\n",
    "        ' IRS ',\n",
    "        'TAX REF',\n",
    "        'RITA',\n",
    "        'CHECK # 746',\n",
    "        'CHECK # 747'\n",
    "    ],\n",
    "    'Transaction Fees': [\n",
    "        'TRANSACTION FEE'\n",
    "    ],\n",
    "    'Visa Payment': [\n",
    "        'INTERNET TRF TO CCA'\n",
    "    ],\n",
    "    'Visa Payment Received': [\n",
    "        'PAYMENT RECEIVED'\n",
    "    ],\n",
    "    'Mortgage': [\n",
    "        'WFHM'\n",
    "    ],\n",
    "    'Bills n Utilities': [\n",
    "        'VERIZON',\n",
    "        'VZWRLSS',\n",
    "        'DOMINION',\n",
    "        'FIRST ENERGY',\n",
    "        'NORTHEAST OHIO',\n",
    "        'CLEVELAND HEIGHTS',\n",
    "        'ENBRIDGE GAS',\n",
    "        'ATT ',\n",
    "        'ATT*BILL',\n",
    "        'NEORSD',\n",
    "        'CWD'\n",
    "    ],\n",
    "    'Medical Insurance': [\n",
    "        'MEDICARE',\n",
    "        'VSP',\n",
    "        'UNITEDHEALTHCARE',\n",
    "        'ROCKWELL',\n",
    "        'AARP HEALTH',\n",
    "        'DELTA DENTAL'\n",
    "    ],\n",
    "    'Car Insurance': [\n",
    "        'LIBERTY MUTUAL'\n",
    "    ],\n",
    "    'Medical and Dental': [\n",
    "        'PEDIATRICS',\n",
    "        'CLEVELAND CLINIC',\n",
    "        'METROHEALTH',\n",
    "        'WESTERN RESERVE PERIO',\n",
    "        'HILLCREST ',\n",
    "        'CLEVELAND KIDNEY ',\n",
    "        'SPRY SENIOR',\n",
    "        'ETNA CLEVELAND',\n",
    "        'HEIGHTS DENTAL '\n",
    "    ],\n",
    "    'Pharmacy': [\n",
    "        'CVS',\n",
    "        'WALGREENS'\n",
    "    ],\n",
    "    'College Tuition': [\n",
    "        'SMARTPAYCIA',\n",
    "        'CASHNET',\n",
    "        'CAMPUS CIA',\n",
    "        'BURREN',\n",
    "        'COLLEGE'\n",
    "    ],\n",
    "    'Art Supplies': [\n",
    "        'UTRECHT',\n",
    "        ' ART '\n",
    "    ],\n",
    "    'Professional Fees': [\n",
    "        'LICENSURE',\n",
    "        'LICENSE',\n",
    "        'CENTER FOR INTUITIVE'\n",
    "    ],\n",
    "    'AI API charges': [\n",
    "        'OPENAI '\n",
    "    ],\n",
    "    'Professional Services': [\n",
    "        'PAUKENLEGAL'\n",
    "    ],\n",
    "    'Liability Insurance': [\n",
    "        'CPH LIABILITY'\n",
    "    ],\n",
    "    'Transportation miscellaneous': [\n",
    "        'Annotate manually'\n",
    "    ],\n",
    "    'Car Registration': [\n",
    "        'BUREAU MOTOR VE'\n",
    "    ],\n",
    "    'Gas': [\n",
    "        'SUNOCO',\n",
    "        'BP',\n",
    "        'SHELL',\n",
    "        'MARATHON',\n",
    "        'CIRCLE K',\n",
    "        'SHEETZ',\n",
    "        'GAS',\n",
    "        'SPEEDWAY'\n",
    "    ],\n",
    "    'Parking and Tolls': [\n",
    "        'EZ PASS REAL TIME',\n",
    "        'GARAG ',\n",
    "        'PARKING SERVICE',\n",
    "        'PARKING CLEVELAND',\n",
    "        'CITY OF CLEVELAND HEIG'\n",
    "    ],\n",
    "    'Car Maintenance': [\n",
    "        'REPAIR',\n",
    "        'AUTO',\n",
    "        'AUTO BODY',\n",
    "        'QUALITY AUTO'\n",
    "    ],\n",
    "    'Groceries': [\n",
    "        'GROCERY',\n",
    "        'HEINEN',\n",
    "        'DAVE',\n",
    "        'WHOLE',\n",
    "        'SODA',\n",
    "        'TRADE'\n",
    "    ],\n",
    "    'Dining Out': [\n",
    "        'COZUMEL CLEVELAND HEIOH',\n",
    "        'TAVERN',\n",
    "        'TOMMYS',\n",
    "        'CAFE',\n",
    "        'WASABI',\n",
    "        'PACIFIC',\n",
    "        'ANATOLIA',\n",
    "        'BATUQUI',\n",
    "        'PHO',\n",
    "        'LAKE HOUSE',\n",
    "        'INDIAN FLAME',\n",
    "        'DEWEY',\n",
    "        'MAROTTA ',\n",
    "        'BANANA',\n",
    "        'BANGKOK',\n",
    "        'HIBACHI',\n",
    "        'BRASSICA',\n",
    "        'RESTAUR',\n",
    "        'BUFFALO',\n",
    "        'COZUMEL',\n",
    "        'FIRST WATCH',\n",
    "        'PARADISE BIRYANI',\n",
    "        'CARIBOU COFFEE',\n",
    "        'STONE OVEN',\n",
    "        'SEOUL GARDEN ',\n",
    "        'YOURS TRULY',\n",
    "        'LOCKKEEPERS',\n",
    "        'MO MO`S KEBAB',\n",
    "        'BAKE ME A WISH',\n",
    "        'ONE POT CLEVELAND'\n",
    "    ],\n",
    "    'Fast Food': [\n",
    "        'LEFTY',\n",
    "        'SHAKE SHACK',\n",
    "        'SHAKESHACK',\n",
    "        'WENDY',\n",
    "        'BUDDA',\n",
    "        'CILANTRO',\n",
    "        'PANERA',\n",
    "        'CHIPOTLE',\n",
    "        'BIBIBOP',\n",
    "        'ROGERS',\n",
    "        'PIADA',\n",
    "        'FIVE GUYS',\n",
    "        'ZINA',\n",
    "        'SUBSHOPPE',\n",
    "        'NATURES OASIS',\n",
    "        'LOTUS EXPRESS',\n",
    "        'JERSEY MIKES',\n",
    "        'SQ *LEVY', # is it Levy fast food and where? \n",
    "        'BRUEGGERS '\n",
    "    ],\n",
    "    'World Food': [\n",
    "        'KRAKOW',\n",
    "        'NIPA HUT',\n",
    "        'YELESEYEVSKY'\n",
    "    ],\n",
    "    'Why DOORDASH?': [\n",
    "        'DOORDASH'\n",
    "    ],\n",
    "    'Aikido n Yoga': [\n",
    "        'CHECK',\n",
    "        ' YOGA'\n",
    "    ],\n",
    "    'Beauty n Supplies': [\n",
    "        'LADIES',\n",
    "        'BATH',\n",
    "        'SALLY BEAUTY',\n",
    "        'AVEDA',\n",
    "        'LUSH BEACHWOOD',\n",
    "        'AIKIKAI',\n",
    "        'AIKIDO',\n",
    "        'ATMA',\n",
    "        'PADDLE',\n",
    "        'OFFICEMAX'\n",
    "    ],\n",
    "    'Sound Bath': [\n",
    "        'PAYPAL INST'\n",
    "    ],\n",
    "    'House Maintenance': [\n",
    "        'HEIGHTS HDWE', # Cle Hts hardware store\n",
    "        re.compile(r'HOME DEPOT.*CLEVELAND'),\n",
    "        re.compile(r'HOME DEPOT.*OH$')\n",
    "    ],\n",
    "    'Furnishing': [\n",
    "        'WORLD',\n",
    "        'REFURNISHING',\n",
    "        'KOALA',\n",
    "        'WAYFAIR'\n",
    "    ],\n",
    "    'Garden': [\n",
    "        'BREMEC',\n",
    "        'LANDSCAPE',\n",
    "        'STUMP',\n",
    "        'NATURE CENTER'\n",
    "    ],\n",
    "    'Subscription': [\n",
    "        'SPOTIFY',\n",
    "        'APPLE',\n",
    "        'NETFLIX',\n",
    "        'AUDIBLE',\n",
    "        'PEACOCK',\n",
    "        'WALL',\n",
    "        'BITDEFENDER',\n",
    "        'MICROSOFT',\n",
    "        'HULU',\n",
    "        'NYTIMES',\n",
    "        'IDEASTREAM',\n",
    "        'WSJ'\n",
    "    ],\n",
    "    'Amazon': [\n",
    "        'AMAZON',\n",
    "        'AMZN'\n",
    "    ],\n",
    "    'Department Store': [\n",
    "        'TARGET',\n",
    "        'MACY'\n",
    "    ],\n",
    "    'Clothes': [\n",
    "        'REI',\n",
    "        'NORDSTROM',\n",
    "        'DICK',\n",
    "        'DSW',\n",
    "        'AVALON',\n",
    "        'MARSHALLS',\n",
    "        'ANN TAYLOR',\n",
    "        'AMERICAN EAGLE',\n",
    "        'FOOTWEAR',\n",
    "        'H&M ',\n",
    "        'OLD NAVY ',\n",
    "        \"VICTORIA'S SECRET\"\n",
    "    ],\n",
    "    'Kindle n Books': [\n",
    "        'KINDLE',\n",
    "        'AUDIOTEKA',\n",
    "        'LOGANBERRY',\n",
    "        \"MAC'S\",\n",
    "        'EMPIK',\n",
    "        'thepolishbookstore' # online bookstore Tytus Romek etc.\n",
    "    ],\n",
    "    'Software n Accessories': [\n",
    "        'SIMON HAYNES',\n",
    "        'ALISTORE',\n",
    "        'GOOGLE',\n",
    "        'FLIXEASY',\n",
    "        'CLIP STUDIO',\n",
    "        'ALIEXPRESS',\n",
    "        'SERIF.COMBILL MINNETONKA MN'\n",
    "    ],\n",
    "    'Computers': [\n",
    "        'MICRO CENTER'\n",
    "    ],\n",
    "    'Personal Electronics': [\n",
    "        'BEST BUY'\n",
    "    ],\n",
    "    'Personal Equipment': [\n",
    "        'Annotate manually'\n",
    "    ],\n",
    "    'Home Supplies n Decor': [\n",
    "        'Annotate manually'\n",
    "    ],\n",
    "    'Gifts': [\n",
    "        'FIDDLEHEAD',\n",
    "        'PASSPORT',\n",
    "        'DIAMONDS FLOWERS',\n",
    "        'BUNDT',\n",
    "        'ALL CITY CANDY',\n",
    "        'LOTUS FLOWER LLC',\n",
    "        'PINKBLUSHMATERNIT',\n",
    "        'LITTLE ROOM ',\n",
    "        'CRAFT COLLECTIVE',\n",
    "        'PANDORA',\n",
    "        'WORDPRESS ', # is it wordpress.com? why a gift?\n",
    "        'STUFFEDANIMALSHOP',\n",
    "        'GETSHIRTZ',\n",
    "        'FLOWERS.COM',\n",
    "        'PROGIFT',\n",
    "        'BERKSHIRE BLANKET'\n",
    "    ],\n",
    "    'Kids Toys': [\n",
    "        'PLAYMATTERS',\n",
    "        'DISNEYSTORE',\n",
    "        'CHILDRENS PLACE',\n",
    "        'LITTLEMARVIN', # little switchboard for Bean\n",
    "        'THECHILDRENSPLACE.COM'\n",
    "    ],\n",
    "    'Cycling n Paddling': [\n",
    "        'BIKES',\n",
    "        'IROCKER',\n",
    "        'OHIO STATE PARKS'\n",
    "    ],\n",
    "    'Cat Food n Supplies': [\n",
    "        'PET',\n",
    "        'CHEWY',\n",
    "        'HOLLYWOOD FEED',\n",
    "        'JACKSON GALAXY'\n",
    "    ],\n",
    "    'Cat Health': [\n",
    "        'VETERINARY'\n",
    "    ],\n",
    "    'Fun Out': [\n",
    "        'CLEVELAND MUSEUM OF AR',\n",
    "        'ClevelandMuseumofNat', # Cleveland Museum of Natural History parking\n",
    "        'CLEV MUS NAT HIST', # Cleveland Museum of Natural History membership\n",
    "        'CHILDRENS MUSEUM ',\n",
    "        'GREATER CLEVELAND AQUA',\n",
    "        'METROPARKS FARMPA KIRTLAND',\n",
    "        'MITCHELL',\n",
    "        'SWEET FIX',\n",
    "        'MANGO MANGO DESSE',\n",
    "        'ON THE RISE',\n",
    "        'RISING STAR COFFEE',\n",
    "        'NERVOUS DOG COFFEE',\n",
    "        'STARBUCKS',\n",
    "        'MICHAELS',\n",
    "        'UPTOWN MART',\n",
    "        'ELLIE-MAYS',\n",
    "        '6 FLAVORS INDIAN',\n",
    "        'LUXE KITCHEN',\n",
    "        'KOKO BAKERY'\n",
    "    ],\n",
    "    'Entertaining and Parties': [\n",
    "        'Annotate manually'\n",
    "    ],\n",
    "    'Movies n Theater': [\n",
    "        'VUDU',\n",
    "        'FANDANGO',\n",
    "        'DOBAMA',\n",
    "        'THEAT',\n",
    "        'CLEVELAND PUBLIC',\n",
    "        'CLEVELAND INSTITUTE OF CLEVELAND',\n",
    "        'MOVIE',\n",
    "        'PRIME VIDEO',\n",
    "        'BORDERLIGHT',\n",
    "        'CINEMA'\n",
    "    ],\n",
    "    'Music n Games': [\n",
    "        'STEAMGAMES',\n",
    "        'BANDCAMP'\n",
    "    ],\n",
    "    'Memberships': [\n",
    "        'Cleveland Museum Cleveland',\n",
    "        'LITCLEVELAND'\n",
    "    ],\n",
    "    'Political Donations': [\n",
    "        'ACTBLUE',\n",
    "        'CUIMC '\n",
    "    ],\n",
    "    'ATM Wthdrw n Dpsit': [\n",
    "        'ATM '\n",
    "    ],\n",
    "    'Vending Machines': [\n",
    "        'VENDING ',\n",
    "        'PEPSIVEN'\n",
    "    ],\n",
    "    'Parcels': [\n",
    "        'USPS '\n",
    "    ],\n",
    "    'Traffic Tickets': [\n",
    "        'Annotate manually'\n",
    "    ],\n",
    "    'Trips Out of Town': [\n",
    "        'Annotate manually'\n",
    "    ],\n",
    "    'Vacation': [\n",
    "        'Annotate manually'\n",
    "    ],\n",
    "    'Air Travel': [\n",
    "        'LOT ',\n",
    "        'AMERICAN',\n",
    "        'EXPEDIA',\n",
    "        'SAS ',\n",
    "        'EAT AND GO JAMAICA',\n",
    "        ' Kastrup',\n",
    "        'HUDSONNEWS ',\n",
    "        'HUDSON',\n",
    "        'HNDISCOVER',\n",
    "        'JFK ',\n",
    "        'MIDTOWN BISTRO',\n",
    "        'TST* ',\n",
    "        'CURRITO '\n",
    "    ],\n",
    "    'Visiting Grandma Ela': [\n",
    "        'PLUSKI',\n",
    "        'OLSZTYN',\n",
    "        'WARSZAWA',\n",
    "        re.compile(r' POL$'),\n",
    "        re.compile(r' CHICAGO IL$')\n",
    "    ],\n",
    "    'Vacation SC': [\n",
    "        'FOLLY',\n",
    "        'VIATORTRIPADVISOR',\n",
    "        'VACASA',\n",
    "        'VRBO',\n",
    "        re.compile(r' SC$'),\n",
    "        re.compile(r' NC$'),\n",
    "        re.compile(r' WV$')\n",
    "    ],\n",
    "    'Visiting Wanda': [\n",
    "        re.compile(r' VA$'),\n",
    "        re.compile(r' GA$'),\n",
    "        re.compile(r' MD$')\n",
    "    ],\n",
    "    'Visiting Eva': [\n",
    "        'PITTSBURGH',\n",
    "        'TURNPIKE',\n",
    "        re.compile(r' PA$')\n",
    "    ],\n",
    "    'Uncategorized': [\n",
    "        'Autogenerated - uncategorized transactions'\n",
    "    ]   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9ee74ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def build_categories_df(categories_to_subcategories_tree, subcategories_to_patterns):\n",
    "    \"\"\"\n",
    "    Build a DataFrame from the categories and subcategories mapping.\n",
    "    \n",
    "    :param categories_to_subcategories_tree: Dictionary mapping categories to their subcategories.\n",
    "    :param subcategories_to_patterns: Dictionary mapping subcategories to their patterns.\n",
    "    :return: DataFrame with columns 'Category', 'Subcategory', 'Pattern', 'IsRegex'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Create a mapping of subcategory ‚Üí category\n",
    "    subcategory_to_category = {\n",
    "        subcat: category\n",
    "        for category, subcats in categories_to_subcategories_tree.items()\n",
    "        for subcat in subcats\n",
    "    }\n",
    "\n",
    "    # Step 2: Assemble the new categories_list\n",
    "    categories_list = []\n",
    "\n",
    "    for subcat, patterns in subcategories_to_patterns.items():\n",
    "        category = subcategory_to_category.get(subcat, 'UNKNOWN')\n",
    "        for pattern in patterns:\n",
    "            pattern_text = pattern.pattern if hasattr(pattern, 'pattern') else pattern\n",
    "            categories_list.append({\n",
    "                'Category': category,\n",
    "                'Subcategory': subcat,\n",
    "                'Pattern': pattern_text,\n",
    "                'IsRegex': hasattr(pattern, 'search')\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "61c880f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories DataFrame sample:\n",
      "  Category        Subcategory             Pattern  IsRegex\n",
      "0   INCOME       Anita Income     ZELLE DEP ANITA    False\n",
      "1   INCOME  Fidelity Transfer                FID     False\n",
      "2   INCOME  KeyBank Cash-Back         KEY REWARDS    False\n",
      "3   INCOME  KeyBank Cash-Back  GIFT FROM KEY BANK    False\n",
      "4    TAXES              Taxes           TAXREFUND    False\n"
     ]
    }
   ],
   "source": [
    "categories_df = build_categories_df(categories_to_subcategories_tree, subcategories_to_patterns)\n",
    "print(\"Categories DataFrame sample:\")\n",
    "print(categories_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c15f3c",
   "metadata": {},
   "source": [
    "To help you validate the integrity of your categorization system, I‚Äôve designed a method that complements your  function. It checks for:\n",
    "\n",
    "### ‚úÖ Validation Goals\n",
    "- \tTypos or mismatches between subcategories and their patterns.\n",
    "- \tEmpty subcategories (no patterns assigned).\n",
    "- \tSubcategories with unknown categories.\n",
    "- \tDuplicate subcategory entries.\n",
    "- \tSuspicious naming (e.g. trailing spaces, unusual characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1b9beb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_category_mappings(categories_to_subcategories_tree, subcategories_to_patterns):\n",
    "    \"\"\"\n",
    "    Validate the integrity of category and subcategory mappings.\n",
    "\n",
    "    Returns a dictionary of issues found, grouped by type.\n",
    "    \"\"\"\n",
    "\n",
    "    issues = {\n",
    "        'missing_subcategory_in_tree': [],\n",
    "        'missing_patterns_for_subcategory': [],\n",
    "        'unknown_category': [],\n",
    "        'duplicate_subcategories': [],\n",
    "        'suspicious_subcategory_names': []\n",
    "    }\n",
    "\n",
    "    # Build subcategory ‚Üí category mapping\n",
    "    subcategory_to_category = {}\n",
    "    for category, subcats in categories_to_subcategories_tree.items():\n",
    "        for subcat in subcats:\n",
    "            if subcat in subcategory_to_category:\n",
    "                issues['duplicate_subcategories'].append(subcat)\n",
    "            subcategory_to_category[subcat] = category\n",
    "\n",
    "            # Check for suspicious naming\n",
    "            if subcat.strip() != subcat or any(c in subcat for c in ['?', '*', '  ']):\n",
    "                issues['suspicious_subcategory_names'].append(subcat)\n",
    "\n",
    "    # Check for subcategories in patterns that aren't in the tree\n",
    "    for subcat in subcategories_to_patterns:\n",
    "        if subcat not in subcategory_to_category:\n",
    "            issues['missing_subcategory_in_tree'].append(subcat)\n",
    "\n",
    "    # Check for subcategories in tree that have no patterns\n",
    "    for subcat in subcategory_to_category:\n",
    "        if subcat not in subcategories_to_patterns or not subcategories_to_patterns[subcat]:\n",
    "            issues['missing_patterns_for_subcategory'].append(subcat)\n",
    "\n",
    "    # Check for subcategories mapped to 'UNKNOWN' category\n",
    "    for subcat in subcategories_to_patterns:\n",
    "        category = subcategory_to_category.get(subcat, 'UNKNOWN')\n",
    "        if category == 'UNKNOWN':\n",
    "            issues['unknown_category'].append(subcat)\n",
    "\n",
    "    return issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ab1e07b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_subcategory_in_tree:\n",
      "  - Traffic Tickets\n",
      "missing_patterns_for_subcategory:\n",
      "  - Trafic Tickets\n",
      "unknown_category:\n",
      "  - Traffic Tickets\n",
      "suspicious_subcategory_names:\n",
      "  - Why DOORDASH?\n"
     ]
    }
   ],
   "source": [
    "issues = validate_category_mappings(categories_to_subcategories_tree, subcategories_to_patterns)\n",
    "\n",
    "for issue_type, entries in issues.items():\n",
    "    if entries:\n",
    "        print(f\"{issue_type}:\")\n",
    "        for entry in entries:\n",
    "            print(f\"  - {entry}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b22a5",
   "metadata": {},
   "source": [
    "### üîç `categorize_transaction(description, categories_df) ‚Üí tuple[str, str]`\n",
    "\n",
    "Attempts to classify a single transaction description into a `(Category, Subcategory)` pair using pattern matching.\n",
    "\n",
    "**Parameters:**\n",
    "- `description` (`str`): Raw transaction description text.\n",
    "- `categories_df` (`pd.DataFrame`): Classification table with columns:\n",
    "  - `'Category'`: Top-level category name.\n",
    "  - `'Subcategory'`: Subcategory name.\n",
    "  - `'Pattern'`: Matching string or regex pattern.\n",
    "  - `'IsRegex'`: Boolean flag indicating regex usage.\n",
    "\n",
    "**Returns:**\n",
    "- `tuple[str, str]`: A `(Category, Subcategory)` pair.\n",
    "  - If a match is found, returns the corresponding category and subcategory.\n",
    "  - If no match is found, returns `('UNCATEGORIZED', 'Uncategorized')`.\n",
    "\n",
    "**Logic:**\n",
    "1. Converts the input `description` to uppercase for case-insensitive matching.\n",
    "2. Iterates over each row in `categories_df`.\n",
    "3. Applies regex search if `IsRegex` is `True`; otherwise checks for substring presence.\n",
    "4. Returns the first matching `(Category, Subcategory)` pair.\n",
    "5. Defaults to `'UNCATEGORIZED'` if no match is found.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "categorize_transaction(\"Payment to ATT*BILL\", categories_df)\n",
    "# ‚Üí ('HOUSING', 'Bills n Utilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ea7f3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize_transaction(description, categories_df):\n",
    "#     \"\"\"\n",
    "#     ### üîç `categorize_transaction(description, categories_df) ‚Üí tuple[str, str]`\n",
    "\n",
    "#     Attempts to classify a single transaction description into a `(Category, Subcategory)` pair using pattern matching.\n",
    "\n",
    "#     **Parameters:**\n",
    "#     - `description` (`str`): Raw transaction description text.\n",
    "#     - `categories_df` (`pd.DataFrame`): Classification table with columns:\n",
    "#     - `'Category'`: Top-level category name.\n",
    "#     - `'Subcategory'`: Subcategory name.\n",
    "#     - `'Pattern'`: Matching string or regex pattern.\n",
    "#     - `'IsRegex'`: Boolean flag indicating regex usage.\n",
    "\n",
    "#     **Returns:**\n",
    "#     - `tuple[str, str]`: A `(Category, Subcategory)` pair.\n",
    "#     - If a match is found, returns the corresponding category and subcategory.\n",
    "#     - If no match is found, returns `('UNCATEGORIZED', 'Uncategorized')`.\n",
    "\n",
    "#     **Logic:**\n",
    "#     1. Converts the input `description` to uppercase for case-insensitive matching.\n",
    "#     2. Iterates over each row in `categories_df`.\n",
    "#     3. Applies regex search if `IsRegex` is `True`; otherwise checks for substring presence.\n",
    "#     4. Returns the first matching `(Category, Subcategory)` pair.\n",
    "#     5. Defaults to `'UNCATEGORIZED'` if no match is found.\n",
    "\n",
    "#     **Example:**\n",
    "#     ```python\n",
    "#     categorize_transaction(\"Payment to ATT*BILL\", categories_df)\n",
    "#     # ‚Üí ('HOUSING', 'Bills n Utilities')\"\"\"\n",
    "#     description_upper = description.upper()\n",
    "\n",
    "#     for _, row in categories_df.iterrows():\n",
    "#         pattern = row['Pattern']\n",
    "#         if row['IsRegex']:\n",
    "#             if re.search(pattern, description_upper, flags=re.IGNORECASE):\n",
    "#                 return row['Category'], row['Subcategory']\n",
    "#         else:\n",
    "#             if pattern.upper() in description_upper:\n",
    "#                 return row['Category'], row['Subcategory']\n",
    "\n",
    "#     return 'UNCATEGORIZED', 'Uncategorized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "6e4b0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize_transactions(raw_transactions, categories_df):\n",
    "#     \"\"\"\n",
    "#     Categorizes transactions in the DataFrame based on the provided categories DataFrame.\n",
    "    \n",
    "#     Parameters:\n",
    "#     raw_transactions (DataFrame): DataFrame containing transactions with a 'Description' column.\n",
    "#     categories_df (DataFrame): DataFrame containing categories and subcategories with patterns.\n",
    "    \n",
    "#     Returns:\n",
    "#     DataFrame: COPY OF THE Original DataFrame with two new columns: 'Category' and 'Subcategory'.\n",
    "#     \"\"\"\n",
    "#     categorized_expenses_df = raw_transactions.copy()\n",
    "#     categorized_expenses_df[['Category', 'Subcategory']] = \\\n",
    "#         raw_transactions['Description'].apply(lambda x: pd.Series(categorize_transaction(x, categories_df)))\n",
    "#     return categorized_expenses_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "02757545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize_transactions_with_annotate(raw_transactions, categories_df):\n",
    "#     \"\"\"\n",
    "#     Categorizes transactions in the DataFrame based on the provided categories DataFrame,\n",
    "#     with optional override via 'Annotation' and passthrough of 'Comments'.\n",
    "\n",
    "#     Parameters:\n",
    "#     raw_transactions (DataFrame): DataFrame containing transactions with a 'Description' column.\n",
    "#                                   Optionally includes 'Annotation' and 'Comments' columns.\n",
    "#     categories_df (DataFrame): DataFrame containing categories and subcategories with patterns.\n",
    "\n",
    "#     Returns:\n",
    "#     DataFrame: Copy of the original DataFrame with new columns: 'Category', 'Subcategory', 'Comments'.\n",
    "#     \"\"\"\n",
    "#     categorized_expenses_df = raw_transactions.copy()\n",
    "\n",
    "#     # Build subcategory ‚Üí category lookup\n",
    "#     subcategory_to_category = {\n",
    "#         row['Subcategory']: row['Category']\n",
    "#         for _, row in categories_df.iterrows()\n",
    "#     }\n",
    "\n",
    "#     def resolve_transaction(row):\n",
    "#         # Check for manual override via Annotation\n",
    "#         annotation = row.get('Annotation')\n",
    "#         if pd.notna(annotation) and annotation in subcategory_to_category:\n",
    "#             return pd.Series({\n",
    "#                 'Category': subcategory_to_category[annotation],\n",
    "#                 'Subcategory': annotation\n",
    "#             })\n",
    "#         # Fallback to pattern matching\n",
    "#         return pd.Series(categorize_transaction(row['Description'], categories_df))\n",
    "\n",
    "#     # Apply categorization logic\n",
    "#     categorized_expenses_df[['Category', 'Subcategory']] = raw_transactions.apply(resolve_transaction, axis=1)\n",
    "\n",
    "#     # Copy Comments if present\n",
    "#     if 'Comments' in raw_transactions.columns:\n",
    "#         categorized_expenses_df['Comments'] = raw_transactions['Comments']\n",
    "\n",
    "#     return categorized_expenses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d4e04ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pair of bank record files for a particular year and month \n",
    "# NOTE - uses standard file naming convention for checking and credit card record  \n",
    "def load_expenses(year_month):\n",
    "    # Load the CSV files with credit card and checking card records\n",
    "    creditcard_filename = 'data/' + year_month + '-A&T-CCard.xlsx'\n",
    "    checking_filename = 'data/' + year_month + '-A&T-CheckingAcct.xlsx'\n",
    "\n",
    "    df_credit = pd.read_excel(creditcard_filename)\n",
    "    df_checking = pd.read_excel(checking_filename)\n",
    "    print(df_credit.head())\n",
    "    print(df_checking.head())\n",
    "\n",
    "    # Check the first few rows to understand the structure of your data.\n",
    "    df = pd.concat([df_checking, df_credit], ignore_index=True)\n",
    "    df.head()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "8fe29fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas display options to show all columns\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "db0df66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year_month = '2025-01'  # Example month\n",
    "# df_monthly_expenses = load_expenses(year_month)\n",
    "# df_monthly_expenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "0fca6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories_df = build_categories_df(categories_to_subcategories_tree, subcategories_to_patterns)\n",
    "# print(categories_df)\n",
    "# categorized_expenses_df = categorize_transactions(df_monthly_expenses, categories_df)\n",
    "# print(categories_df)\n",
    "# print(categorized_expenses_df.head())\n",
    "# print(categorized_expenses_df[['Description', 'Subcategory', 'Category']].head(10))  # first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "a42d6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_uncategorized_transactions(categorized_expenses_df):\n",
    "    \"\"\"\n",
    "    Show uncategorized transactions from the categorized DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    categorized_expenses_df (DataFrame): DataFrame with categorized transactions.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: DataFrame containing uncategorized transactions.\n",
    "    \"\"\"\n",
    "    uncategorized = categorized_expenses_df[categorized_expenses_df['Category'] == 'UNCATEGORIZED']\n",
    "    print(f\"{len(uncategorized)} uncategorized transactions\")\n",
    "    return uncategorized[['Date', 'Amount', 'Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "5681961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_date_format(categorized_expenses_df):\n",
    "    \"\"\"\n",
    "    Correct the date format in the categorized expenses DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    categorized_expenses_df (DataFrame): DataFrame with a 'Date' column to be corrected.\n",
    "    \n",
    "    Returns:\n",
    "    None: The DataFrame is modified in place.\n",
    "    \"\"\"\n",
    "    # Convert 'Date' column to datetime format and then to string in 'YYYY-MM-DD' format\n",
    "    categorized_expenses_df['Date'] = pd.to_datetime(categorized_expenses_df['Date']).dt.strftime('%Y-%m-%d')\n",
    "    categorized_expenses_df['Date'] = pd.to_datetime(categorized_expenses_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7686de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of ExcelWriter to manage Excel formatting and saving workbook and sheet\n",
    "def UseExcelWriter(categorized_expenses_df, year_month):\n",
    "    \"\"\"\n",
    "    Use of ExcelWriter to manage Excel formatting and saving workbook and sheet.\n",
    "    \"\"\"\n",
    "    output_path = 'categorized_transactions' + year_month + '_formatted.xlsx'\n",
    "    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "        # Write your DataFrame\n",
    "        categorized_expenses_df.to_excel(writer, sheet_name='Expenses', index=False)\n",
    "\n",
    "        # Access Excel components\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Expenses']\n",
    "\n",
    "        # Apply formatting to a column (e.g. Date)\n",
    "        date_format = workbook.add_format({'num_format': 'yyyy-mm-dd'})\n",
    "        worksheet.set_column('A:A', 15, date_format)  # Assuming column A is 'Date'\n",
    "\n",
    "    # ‚úÖ File is written and closed when the 'with' block ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "85bb763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(categorized_expenses_df, year_month, long_format=False):\n",
    "    \"\"\"\n",
    "    Save the categorized expenses DataFrame to an Excel file.\n",
    "    \n",
    "    Parameters:\n",
    "    categorized_expenses_df (DataFrame): DataFrame with categorized expenses.\n",
    "    year_month (str): Year and month string to include in the filename.\n",
    "    \n",
    "    Returns:\n",
    "    None: The DataFrame is saved to an Excel file.\n",
    "    \"\"\"\n",
    "\n",
    "    if long_format:\n",
    "        # Save in long format\n",
    "        output_path = 'categorized_transactions' + year_month + '_filtered.xlsx'\n",
    "        categorized_expenses_df[['Date', 'Description', 'Amount', 'Subcategory', 'Category']].to_excel(output_path, index=False)\n",
    "    else:\n",
    "        output_path = 'categorized_transactions' + year_month + '.xlsx'\n",
    "        # format the 'Date' column to 'YYYY-MM-DD' and save to Excel\n",
    "        categorized_expenses_df['Date'] = pd.to_datetime(categorized_expenses_df['Date']).dt.strftime('%Y-%m-%d')\n",
    "        categorized_expenses_df.to_excel(output_path, index=False)\\\n",
    "\n",
    "    print(f\"‚úÖ Saved categorized results to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "3fc9a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "class MonthlyExpenseReport:\n",
    "    def __init__(self, year_month: str):\n",
    "        \"\"\"\n",
    "        Initialize with a raw transaction DataFrame and metadata\n",
    "        \"\"\"\n",
    "        self.year_month = year_month  # format: 'yy-mm'\n",
    "        self.categories_df =  build_categories_df(categories_to_subcategories_tree, subcategories_to_patterns)\n",
    "        self.transactions_raw = load_expenses(self.year_month)\n",
    "        self.transactions_categorized = None\n",
    "        self.summary_table = None\n",
    "\n",
    "    def read_bank_records(self):\n",
    "        \"\"\" read bank records for a given month\"\"\"\n",
    "        self.transactions_raw = load_expenses(self.year_month)  \n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"Ensure proper datetime format and extract YearMonth label\"\"\"\n",
    "        self.transactions_raw['Date'] = pd.to_datetime(self.transactions_raw['Date'])\n",
    "        # self.transactions_raw['YearMonth'] = self.transactions_raw['Date'].dt.strftime('%y-%m')\n",
    "\n",
    "    def categorize_transactions(self):\n",
    "        \"\"\"Apply pattern matching and build categorized DataFrame\"\"\"\n",
    "        def _categorize_row(row):\n",
    "            desc = row['Description']\n",
    "            for _, rule in self.categories_df.iterrows():\n",
    "                pat = rule['Pattern']\n",
    "                if rule['IsRegex']:\n",
    "                    if re.search(pat, desc, flags=re.IGNORECASE):\n",
    "                        return pd.Series([rule['Subcategory'], rule['Category']])\n",
    "                else:\n",
    "                    if pat.upper() in desc.upper():\n",
    "                        return pd.Series([rule['Subcategory'], rule['Category']])\n",
    "            return pd.Series(['Uncategorized', 'UNCATEGORIZED'])\n",
    "\n",
    "        df = self.transactions_raw.copy()\n",
    "        df[['Subcategory', 'Category']] = df.apply(_categorize_row, axis=1)\n",
    "        self.transactions_categorized = df\n",
    "\n",
    "    def categorize_transactions_with_annotate(self):\n",
    "        \"\"\"Categorize transactions using Annotation override or pattern matching on Description.\"\"\"\n",
    "\n",
    "        # Build subcategory ‚Üí category lookup\n",
    "        subcategory_to_category = {\n",
    "            row['Subcategory']: row['Category']\n",
    "            for _, row in self.categories_df.iterrows()\n",
    "        }\n",
    "\n",
    "        def _categorize_row(row):\n",
    "            # Manual override via Annotation\n",
    "            annotation = row.get('Annotation')\n",
    "            if pd.notna(annotation) and annotation in subcategory_to_category:\n",
    "                return pd.Series({\n",
    "                    'Subcategory': annotation,\n",
    "                    'Category': subcategory_to_category[annotation]\n",
    "                })\n",
    "\n",
    "            # If no Annotation, use pattern matching on Description\n",
    "            description = row.get('Description', '')\n",
    "            # Iterate over all category definitions in dataframe\n",
    "            for _, category_definition in self.categories_df.iterrows():\n",
    "                # Identify whetehr to use regex or simple substring match\n",
    "                pattern = category_definition['Pattern']\n",
    "                if category_definition['IsRegex']:\n",
    "                    if re.search(pattern, description, flags=re.IGNORECASE):\n",
    "                        return pd.Series({\n",
    "                            'Subcategory': category_definition['Subcategory'],\n",
    "                            'Category': category_definition['Category']\n",
    "                        })\n",
    "                else:\n",
    "                    if pattern.upper() in description.upper():\n",
    "                        return pd.Series({\n",
    "                            'Subcategory': category_definition['Subcategory'],\n",
    "                            'Category': category_definition['Category']\n",
    "                        })\n",
    "\n",
    "            return pd.Series({'Subcategory': 'Uncategorized', 'Category': 'UNCATEGORIZED'})\n",
    "\n",
    "        # Apply categorization\n",
    "        df = self.transactions_raw.copy()\n",
    "        df[['Subcategory', 'Category']] = df.apply(_categorize_row, axis=1)\n",
    "\n",
    "        # Remove Annotation column if present\n",
    "        if 'Annotation' in df.columns:\n",
    "            df.drop(columns='Annotation', inplace=True)\n",
    "\n",
    "        # Move Comments to the end if present\n",
    "        if 'Comments' in df.columns:\n",
    "            df = df[[col for col in df.columns if col != 'Comments'] + ['Comments']]\n",
    "\n",
    "        self.transactions_categorized = df\n",
    "\n",
    "    def summarize(self):\n",
    "        \"\"\"Creates a cleanly indexed summary table with real category + subcategory labels and correct totals.\"\"\"\n",
    "\n",
    "        # Ordered structure from category tree\n",
    "        cat_sub_list = [\n",
    "            (category, subcat)\n",
    "            for category, subcats in categories_to_subcategories_tree.items()\n",
    "            for subcat in subcats\n",
    "        ]\n",
    "        cat_sub_index = pd.MultiIndex.from_tuples(\n",
    "            cat_sub_list, names=['Category', 'Subcategory']\n",
    "        )\n",
    "        print(\"cat_sub_index sample:\", cat_sub_index.tolist()[:10])\n",
    "\n",
    "        # Group actual expenses by category/subcategory (returns a Series!)\n",
    "        grouped_series = (\n",
    "            self.transactions_categorized\n",
    "            .groupby(['Category', 'Subcategory'])['Amount']\n",
    "            .sum()\n",
    "        )\n",
    "\n",
    "        # Convert to DataFrame explicitly and reindex\n",
    "        grouped_df = grouped_series.to_frame(name='Amount') \\\n",
    "            .reindex(cat_sub_index, fill_value=0) \\\n",
    "            .reset_index()\n",
    "\n",
    "        # Final column cleanup\n",
    "        grouped_df.rename(columns={\n",
    "            'Category': 'CATEGORIES',\n",
    "            'Subcategory': 'SUBCATEGORIES',\n",
    "            'Amount': 'AMOUNT'\n",
    "        }, inplace=True)\n",
    "\n",
    "        # ... after grouped_df is created and columns are renamed ...\n",
    "        ordered_index = pd.MultiIndex.from_tuples(\n",
    "            [\n",
    "                (cat, subcat)\n",
    "                for cat, subcats in categories_to_subcategories_tree.items()\n",
    "                for subcat in subcats\n",
    "            ],\n",
    "            names=['CATEGORIES', 'SUBCATEGORIES']\n",
    "        )\n",
    "        # Enforce semantic order\n",
    "        self.summary_table = (\n",
    "            grouped_df\n",
    "            .set_index(['CATEGORIES', 'SUBCATEGORIES'])\n",
    "            .reindex(ordered_index, fill_value=0)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        self.summary_table = grouped_df\n",
    "\n",
    "    def export_summary_excel(self, output_path: str):\n",
    "        \"\"\"Save summary table with clean formatting and custom sheet name\"\"\"\n",
    "        sheet_name = f\"Summary_{self.year_month}\"\n",
    "\n",
    "        print(\"Summary table:\\n\", self.summary_table.head(10))\n",
    "        print(\"Columns:\", self.summary_table.columns.tolist())\n",
    "\n",
    "        with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "            self.summary_table.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "            # Format columns\n",
    "            header_format = workbook.add_format({'bold': True})\n",
    "            money_format = workbook.add_format({'num_format': '$#,##0.00'})\n",
    "\n",
    "            # Set column widths and formats by header\n",
    "            worksheet.set_column('A:A', 22, None)         # CATEGORIES\n",
    "            worksheet.set_column('B:B', 26, None)         # SUBCATEGORIES\n",
    "            worksheet.set_column('C:C', 15, money_format) # AMOUNT\n",
    "\n",
    "            # Bold headers (optional, decorative)\n",
    "            for col_num, value in enumerate(self.summary_table.columns):\n",
    "                worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "    def export_transactions_excel(self, output_path: str):\n",
    "        \"\"\"Export full transaction list with formatted dates\"\"\"\n",
    "        df = self.transactions_categorized.copy()\n",
    "        df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "        df.to_excel(output_path, index=False, sheet_name=f'Tnxs_{self.year_month}')\n",
    "\n",
    "    def run_full_pipeline(self, use_annotation: bool=True):\n",
    "        \"\"\"Convenience method\"\"\"\n",
    "        self.preprocess()\n",
    "        if use_annotation:\n",
    "            self.categorize_transactions_with_annotate()\n",
    "        else: \n",
    "            self.categorize_transactions()\n",
    "        self.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "26900d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiMonthExpenseWorkbook:\n",
    "    def __init__(self, reports: list[MonthlyExpenseReport]):\n",
    "        self.reports = reports\n",
    "        self.summary_pivot = None\n",
    "\n",
    "    def enforce_semantic_order(self):\n",
    "        ordered_pairs = [\n",
    "            (cat, subcat)\n",
    "            for cat, subcats in categories_to_subcategories_tree.items()\n",
    "            for subcat in subcats\n",
    "        ]\n",
    "\n",
    "        # Reindex the merged summary_pivot\n",
    "        self.summary_pivot = (\n",
    "            self.summary_pivot\n",
    "            .set_index(['CATEGORIES', 'SUBCATEGORIES'])\n",
    "            .reindex(ordered_pairs, fill_value=0)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Ensure the columns are in the correct order\n",
    "        # Capture fixed columns\n",
    "        fixed_cols = ['CATEGORIES', 'SUBCATEGORIES']\n",
    "        # Extract and sort month columns\n",
    "        month_cols = sorted(\n",
    "            [col for col in self.summary_pivot.columns if col not in fixed_cols]\n",
    "        )\n",
    "        # Reorder DataFrame\n",
    "        self.summary_pivot = self.summary_pivot[fixed_cols + month_cols]        \n",
    "\n",
    "        \n",
    "    def build_combined_summary(self):\n",
    "        \"\"\"Pivot all monthly summaries into a single table.\"\"\"\n",
    "        summary_frames = []\n",
    "\n",
    "        for report in self.reports:\n",
    "            df = report.summary_table.copy()\n",
    "            df = df.rename(columns={'AMOUNT': report.year_month})\n",
    "            summary_frames.append(df)\n",
    "\n",
    "        merged = summary_frames[0][['CATEGORIES', 'SUBCATEGORIES', self.reports[0].year_month]]\n",
    "\n",
    "        for df in summary_frames[1:]:\n",
    "            merged = merged.merge(df, on=['CATEGORIES', 'SUBCATEGORIES'], how='outer')\n",
    "\n",
    "        merged.fillna(0, inplace=True)\n",
    "        self.summary_pivot = merged\n",
    "\n",
    "    def export_all_to_excel(self, output_path: str):\n",
    "        \"\"\"Save summary and all transaction sheets to a single workbook.\"\"\"\n",
    "        self.build_combined_summary()\n",
    "        self.enforce_semantic_order()\n",
    "\n",
    "        with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "            # Write the combined summary first\n",
    "            self.summary_pivot.to_excel(writer, sheet_name='Monthly Summary', index=False)\n",
    "\n",
    "            # Format summary\n",
    "            workbook = writer.book\n",
    "            summary_ws = writer.sheets['Monthly Summary']\n",
    "            currency_fmt = workbook.add_format({'num_format': '$#,##0.00'})\n",
    "            summary_ws.set_column('A:B', 22)  # Categories/Subcategories\n",
    "            summary_ws.set_column(2, 1 + len(self.reports), 14, currency_fmt)\n",
    "\n",
    "            # Write each month's transactions sheet\n",
    "            for report in self.reports:\n",
    "                sheet_name = f\"Txns_{report.year_month}\"\n",
    "                df = report.transactions_categorized.copy()\n",
    "                df = df.sort_values('Date')  # ‚Üê this ensures chronological order\n",
    "                df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "                # Optional formatting for txn sheets\n",
    "                tx_ws = writer.sheets[sheet_name]\n",
    "                tx_ws.set_column('A:A', 14)  # Date\n",
    "                tx_ws.set_column('B:B', 40)  # Description\n",
    "                tx_ws.set_column('C:D', 15)  # Amount + Type\n",
    "\n",
    "                tx_ws.freeze_panes(1, 0)  # Keeps header row visible while scrolling\n",
    "                tx_ws.autofilter(0, 0, df.shape[0], df.shape[1] - 1)  # Enables filtering on all columns\n",
    "\n",
    "                # Dynamically adjust each column width based on content\n",
    "                for i, col in enumerate(df.columns):\n",
    "                    # Get max width between header and the longest string in the column\n",
    "                    max_len = max(\n",
    "                        df[col].astype(str).map(len).max(),\n",
    "                        len(str(col))\n",
    "                    ) + 2  # optional padding for readability\n",
    "\n",
    "                    tx_ws.set_column(i, i, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "25d35694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Amount                             Description  Ref.# Annotation Comments\n",
      "0 2025-08-29 -324.99      WHOLEFDS CTR 10199 UNIVERSITY HTOH   6089        NaN      NaN\n",
      "1 2025-08-31  -44.19  DAVE'S SUPERMARKET #22 CLEVELAND HTSOH   4123        NaN      NaN\n",
      "2 2025-08-30  -58.19    THE HOME DEPOT #3818 CLEVELAND HGTOH   4123        NaN      NaN\n",
      "3 2025-08-30  -45.33              SP SODA SENSE GREEN BAY WI   4123        NaN      NaN\n",
      "4 2025-08-30   -5.00     ideastream Public Medi CLEVELAND OH   4123        NaN      NaN\n",
      "        Date   Amount                                Description  Ref.# Annotation Comments\n",
      "0 2025-08-29 -7331.30  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN        NaN      NaN\n",
      "1 2025-08-28   -14.00                 VSP INSURANCE COCORP PYMNT    NaN        NaN      NaN\n",
      "2 2025-08-27  -177.70                   VERIZON WIRELESSPAYMENTS    NaN        NaN      NaN\n",
      "3 2025-08-27 -1490.75       BILL PAY:WFHM 708 XXXXX7939 6BA12IXC    NaN        NaN      NaN\n",
      "4 2025-08-26  3000.00        ZELLE DEP ANITA S DACANAY XBZ1HIG7C    NaN        NaN      NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n",
      "Summary table:\n",
      "   CATEGORIES          SUBCATEGORIES   AMOUNT\n",
      "0     INCOME           Anita Income  6200.00\n",
      "1     INCOME      Fidelity Transfer  9000.00\n",
      "2     INCOME      KeyBank Cash-Back     0.00\n",
      "3      TAXES                  Taxes     0.00\n",
      "4       FEES       Transaction Fees    -0.33\n",
      "5    EXCLUDE           Visa Payment -7331.30\n",
      "6    EXCLUDE  Visa Payment Received  7331.30\n",
      "7    HOUSING               Mortgage -1490.75\n",
      "8    HOUSING      Bills n Utilities  -768.62\n",
      "9  INSURANCE      Medical Insurance -1714.85\n",
      "Columns: ['CATEGORIES', 'SUBCATEGORIES', 'AMOUNT']\n",
      "        Date  Amount                             Description  Ref.# Annotation Comments\n",
      "0 2025-08-29 -324.99      WHOLEFDS CTR 10199 UNIVERSITY HTOH   6089        NaN      NaN\n",
      "1 2025-08-31  -44.19  DAVE'S SUPERMARKET #22 CLEVELAND HTSOH   4123        NaN      NaN\n",
      "2 2025-08-30  -58.19    THE HOME DEPOT #3818 CLEVELAND HGTOH   4123        NaN      NaN\n",
      "3 2025-08-30  -45.33              SP SODA SENSE GREEN BAY WI   4123        NaN      NaN\n",
      "4 2025-08-30   -5.00     ideastream Public Medi CLEVELAND OH   4123        NaN      NaN\n",
      "        Date   Amount                                Description  Ref.# Annotation Comments\n",
      "0 2025-08-29 -7331.30  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN        NaN      NaN\n",
      "1 2025-08-28   -14.00                 VSP INSURANCE COCORP PYMNT    NaN        NaN      NaN\n",
      "2 2025-08-27  -177.70                   VERIZON WIRELESSPAYMENTS    NaN        NaN      NaN\n",
      "3 2025-08-27 -1490.75       BILL PAY:WFHM 708 XXXXX7939 6BA12IXC    NaN        NaN      NaN\n",
      "4 2025-08-26  3000.00        ZELLE DEP ANITA S DACANAY XBZ1HIG7C    NaN        NaN      NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n",
      "Summary table:\n",
      "   CATEGORIES          SUBCATEGORIES   AMOUNT\n",
      "0     INCOME           Anita Income  6200.00\n",
      "1     INCOME      Fidelity Transfer  9000.00\n",
      "2     INCOME      KeyBank Cash-Back     0.00\n",
      "3      TAXES                  Taxes     0.00\n",
      "4       FEES       Transaction Fees    -0.33\n",
      "5    EXCLUDE           Visa Payment -7331.30\n",
      "6    EXCLUDE  Visa Payment Received  7331.30\n",
      "7    HOUSING               Mortgage -1490.75\n",
      "8    HOUSING      Bills n Utilities  -768.62\n",
      "9  INSURANCE      Medical Insurance -1714.85\n",
      "Columns: ['CATEGORIES', 'SUBCATEGORIES', 'AMOUNT']\n"
     ]
    }
   ],
   "source": [
    "month_label = '2025-08'\n",
    "\n",
    "# jan_df = load_expenses(month_label)\n",
    "# df_monthly_expenses.head()\n",
    "\n",
    "report = MonthlyExpenseReport(year_month=month_label)\n",
    "report.run_full_pipeline(use_annotation=False)\n",
    "\n",
    "# Save results\n",
    "report.export_transactions_excel(f'monthly_categorized_transactions_{month_label}.xlsx')\n",
    "report.export_summary_excel(f'monthly_summary_{month_label}.xlsx')\n",
    "\n",
    "annotated_report = MonthlyExpenseReport(year_month=month_label)\n",
    "annotated_report.run_full_pipeline(use_annotation=True)\n",
    "\n",
    "# Save results\n",
    "annotated_report.export_transactions_excel(f'monthly_categorized_transactions_{month_label}_annotated.xlsx')\n",
    "annotated_report.export_summary_excel(f'monthly_summary_{month_label}_annotated.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "98308473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan_25_label = '2025-01'\n",
    "# Feb_25_label = '2025-02'\n",
    "# Mar_25_label = '2025-03'\n",
    "# Apr_25_label = '2025-04'\n",
    "\n",
    "# jan_report = MonthlyExpenseReport(year_month=Jan_25_label)\n",
    "# feb_report = MonthlyExpenseReport(year_month=Feb_25_label)\n",
    "# mar_report = MonthlyExpenseReport(year_month=Mar_25_label)\n",
    "# apr_report = MonthlyExpenseReport(year_month=Apr_25_label)\n",
    "\n",
    "# all_reports = [jan_report, feb_report, mar_report]\n",
    "# book = MultiMonthExpenseWorkbook(all_reports)\n",
    "# book.export_all_to_excel(\"q1_expenses_summary.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "6c555cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Amount                            Description  Ref.# Annotation Comments\n",
      "0 2025-05-31 -273.08     WHOLEFDS CTR 10199 UNIVERSITY HTOH   6089        NaN      NaN\n",
      "1 2025-05-30  -34.54  BREMEC ON THE HEIGHTS CLEVELAND HEIOH   6089        NaN      NaN\n",
      "2 2025-05-29  -31.19  SUNOCO 0756490900 QPS CLEVELAND HEIOH   6089        NaN      NaN\n",
      "3 2025-05-30  -87.75     THE TAVERN COMPANY CLEVELAND HEIOH   4123        NaN      NaN\n",
      "4 2025-05-30  -39.31   THE HOME DEPOT #3818 CLEVELAND HGTOH   4123        NaN      NaN\n",
      "        Date   Amount                                Description  Ref.# Annotation Comments\n",
      "0 2025-05-30 -6489.40  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN        NaN      NaN\n",
      "1 2025-05-30 -2450.00                                CHECK # 752  752.0        NaN      NaN\n",
      "2 2025-05-28   -61.98                                CWD WEB PAY    NaN        NaN      NaN\n",
      "3 2025-05-28   -14.00                 VSP INSURANCE COCORP PYMNT    NaN        NaN      NaN\n",
      "4 2025-05-28  -206.35                 ATT*BILL PAYMENT DALLAS TX    NaN        NaN      NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n",
      "        Date   Amount                             Description  Ref.#\n",
      "0 2025-05-01  4709.24           PAYMENT RECEIVED -- THANK YOU   4123\n",
      "1 2025-04-30    -5.00     ideastream Public Medi CLEVELAND OH   4123\n",
      "2 2025-04-30   -21.59  MAC'S BACKS-BOOKS ON C CLEVELAND HTSOH   4123\n",
      "3 2025-04-30   -12.95                   SPOTIFY 8777781161 NY   4123\n",
      "4 2025-04-30   -59.99       FLOWER SHOP NETWORK 8773767363 AR   4123\n",
      "        Date   Amount                                Description  Ref.#\n",
      "0 2025-05-01 -4709.24  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN\n",
      "1 2025-04-29   -55.61                                CWD WEB PAY    NaN\n",
      "2 2025-04-28  -176.81                   VERIZON WIRELESSPAYMENTS    NaN\n",
      "3 2025-04-28   -14.00                 VSP INSURANCE COCORP PYMNT    NaN\n",
      "4 2025-04-28  -206.35                 ATT*BILL PAYMENT DALLAS TX    NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n",
      "        Date   Amount                             Description  Ref.# Annotation Comments\n",
      "0 2025-08-01  5011.14           PAYMENT RECEIVED -- THANK YOU   4123        NaN      NaN\n",
      "1 2025-07-31    -0.69                 FOREIGN TRANSACTION FEE   4123        NaN      NaN\n",
      "2 2025-07-31   -22.97           thepolishbookstore.com Poznan   4123        NaN      NaN\n",
      "3 2025-07-30    -5.00     ideastream Public Medi CLEVELAND OH   4123        NaN      NaN\n",
      "4 2025-07-30   -60.24  DAVE'S SUPERMARKET #22 CLEVELAND HTSOH   4123        NaN      NaN\n",
      "        Date   Amount                                Description  Ref.#\n",
      "0 2025-08-01 -5011.14  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN\n",
      "1 2025-07-29   -55.61                                CWD WEB PAY    NaN\n",
      "2 2025-07-29 -1490.75       BILL PAY:WFHM 708 XXXXX7939 EBA1T7RG    NaN\n",
      "3 2025-07-28  -194.58                   VERIZON WIRELESSPAYMENTS    NaN\n",
      "4 2025-07-28   -14.00                 VSP INSURANCE COCORP PYMNT    NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n",
      "        Date   Amount                           Description  Ref.#\n",
      "0 2025-07-01  5073.97         PAYMENT RECEIVED -- THANK YOU   4123\n",
      "1 2025-06-30    -5.00   ideastream Public Medi CLEVELAND OH   4123\n",
      "2 2025-06-30   -12.95                 SPOTIFY 8777781161 NY   4123\n",
      "3 2025-06-30   -37.99             TRADE COFFEE CO BOSTON MA   4123\n",
      "4 2025-06-30  -234.67  HOTELCOM72063951735351 HOTELS.COM WA   4123\n",
      "        Date   Amount                                Description  Ref.#\n",
      "0 2025-07-01 -5073.97  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN\n",
      "1 2025-06-30   -14.00                 VSP INSURANCE COCORP PYMNT    NaN\n",
      "2 2025-06-30  5000.00                  FID BKG SVC LLC MONEYLINE    NaN\n",
      "3 2025-06-27  -193.77                   VERIZON WIRELESSPAYMENTS    NaN\n",
      "4 2025-06-27 -1490.75       BILL PAY:WFHM 708 XXXXX7939 LBU1DH95    NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n",
      "        Date  Amount                       Description  Ref.#\n",
      "0 2025-02-28  -27.71   SUNOCO 0813639200 QPS VERONA PA   4123\n",
      "1 2025-02-28   -4.87  STARBUCKS 75941 420170 VERONA PA   4123\n",
      "2 2025-02-28  -12.95             SPOTIFY 8777781161 NY   4123\n",
      "3 2025-02-28  -77.19           SUSHI BAE WOODBRIDGE VA   4123\n",
      "4 2025-02-28   -6.47    VUDU.COM FANDANGO SUNNYVALE CA   4123\n",
      "        Date   Amount                                Description  Ref.#\n",
      "0 2025-02-28 -7544.87  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN\n",
      "1 2025-02-28   -14.00                 VSP INSURANCE COCORP PYMNT    NaN\n",
      "2 2025-02-27  -175.64                   VERIZON WIRELESSPAYMENTS    NaN\n",
      "3 2025-02-27   -61.98                                CWD WEB PAY    NaN\n",
      "4 2025-02-26 -1220.50                  LIBERTY MUTUAL INSRNC PMT    NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n",
      "        Date  Amount                             Description  Ref.# Annotation Comments\n",
      "0 2025-08-29 -324.99      WHOLEFDS CTR 10199 UNIVERSITY HTOH   6089        NaN      NaN\n",
      "1 2025-08-31  -44.19  DAVE'S SUPERMARKET #22 CLEVELAND HTSOH   4123        NaN      NaN\n",
      "2 2025-08-30  -58.19    THE HOME DEPOT #3818 CLEVELAND HGTOH   4123        NaN      NaN\n",
      "3 2025-08-30  -45.33              SP SODA SENSE GREEN BAY WI   4123        NaN      NaN\n",
      "4 2025-08-30   -5.00     ideastream Public Medi CLEVELAND OH   4123        NaN      NaN\n",
      "        Date   Amount                                Description  Ref.# Annotation Comments\n",
      "0 2025-08-29 -7331.30  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN        NaN      NaN\n",
      "1 2025-08-28   -14.00                 VSP INSURANCE COCORP PYMNT    NaN        NaN      NaN\n",
      "2 2025-08-27  -177.70                   VERIZON WIRELESSPAYMENTS    NaN        NaN      NaN\n",
      "3 2025-08-27 -1490.75       BILL PAY:WFHM 708 XXXXX7939 6BA12IXC    NaN        NaN      NaN\n",
      "4 2025-08-26  3000.00        ZELLE DEP ANITA S DACANAY XBZ1HIG7C    NaN        NaN      NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n",
      "        Date   Amount                          Description  Ref.#\n",
      "0 2025-04-01  7402.00        PAYMENT RECEIVED -- THANK YOU   4123\n",
      "1 2025-03-31   -20.52    Etsy.com*Jazminefield BROOKLYN NY   6089\n",
      "2 2025-03-30    -5.00  ideastream Public Medi CLEVELAND OH   4123\n",
      "3 2025-03-30  -274.75   WHOLEFDS CTR 10199 UNIVERSITY HTOH   6089\n",
      "4 2025-03-30   -16.48      PETSMART # 2313 UNIVERSITY HEOH   6089\n",
      "        Date   Amount                                Description  Ref.#\n",
      "0 2025-04-01 -7402.00  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN\n",
      "1 2025-03-31  -926.00                                CHECK # 746  746.0\n",
      "2 2025-03-28   -55.61                                CWD WEB PAY    NaN\n",
      "3 2025-03-28   -14.00                 VSP INSURANCE COCORP PYMNT    NaN\n",
      "4 2025-03-28 -1487.31       BILL PAY:WFHM 708 XXXXX7939 VBZ18GKC    NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n",
      "        Date   Amount                             Description  Ref.#\n",
      "0 2025-01-31   -91.72           T J MAXX #875 SOUTH EUCLID OH   6089\n",
      "1 2025-01-31  -285.36  HEINEN'S GROCERY STORE SHAKER HEIGHTOH   6089\n",
      "2 2025-01-31  6133.73           PAYMENT RECEIVED -- THANK YOU   4123\n",
      "3 2025-01-30   -36.56  DAVE'S SUPERMARKET #22 CLEVELAND HTSOH   6089\n",
      "4 2025-01-30   -12.95                   SPOTIFY 8777781161 NY   4123\n",
      "        Date   Amount                                Description  Ref.#\n",
      "0 2025-01-31 -6133.73  INTERNET TRF TO CCA XXXXXXXXXXXX4123 0101    NaN\n",
      "1 2025-01-31  -131.32                             NEORSD WEB PAY    NaN\n",
      "2 2025-01-31   -56.08          ENBRIDGE GAS OHIBILLPAY XXXXX1403    NaN\n",
      "3 2025-01-29 -1487.31       BILL PAY:WFHM 708 XXXXX7939 PB51TFEM    NaN\n",
      "4 2025-01-28  -211.51                   VERIZON WIRELESSPAYMENTS    NaN\n",
      "cat_sub_index sample: [('INCOME', 'Anita Income'), ('INCOME', 'Fidelity Transfer'), ('INCOME', 'KeyBank Cash-Back'), ('TAXES', 'Taxes'), ('FEES', 'Transaction Fees'), ('EXCLUDE', 'Visa Payment'), ('EXCLUDE', 'Visa Payment Received'), ('HOUSING', 'Mortgage'), ('HOUSING', 'Bills n Utilities'), ('INSURANCE', 'Medical Insurance')]\n"
     ]
    }
   ],
   "source": [
    "month_labels = {\n",
    "    '2025-01',\n",
    "    '2025-02',\n",
    "    '2025-03',\n",
    "    '2025-04',\n",
    "    '2025-05',\n",
    "    '2025-06',\n",
    "    '2025-07',\n",
    "    '2025-08'\n",
    "}\n",
    "summary_label = '2025-01_to_08'\n",
    "\n",
    "reports = []\n",
    "\n",
    "for month_label in month_labels:\n",
    "    report = MonthlyExpenseReport(year_month=month_label)\n",
    "    report.run_full_pipeline()  # ‚Üê This processes everything\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "ba20aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "book = MultiMonthExpenseWorkbook(reports)\n",
    "book.export_all_to_excel(f'multimonth_expense_summary_{summary_label}.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ant-finances-analysis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
